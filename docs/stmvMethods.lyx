#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin /home/jae/docs/stmv/
\textclass paper
\use_default_options true
\begin_modules
theorems-ams
eqs-within-sections
figs-within-sections
\end_modules
\maintain_unincluded_children false
\language english
\language_package none
\inputencoding utf8
\fontencoding global
\font_roman "times" "default"
\font_sans "helvet" "default"
\font_typewriter "courier" "default"
\font_math "newtxmath" "auto"
\font_default_family rmdefault
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_bookmarks false
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks true
\pdf_pdfborder true
\pdf_colorlinks false
\pdf_backref section
\pdf_pdfusetitle true
\papersize default
\use_geometry true
\use_package amsmath 2
\use_package amssymb 2
\use_package cancel 0
\use_package esint 1
\use_package mathdots 0
\use_package mathtools 0
\use_package mhchem 0
\use_package stackrel 0
\use_package stmaryrd 0
\use_package undertilde 0
\cite_engine natbib
\cite_engine_type authoryear
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation skip
\defskip bigskip
\is_math_indent 0
\math_numbering_side default
\quotes_style plain
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Spatiotemporal models of variability – continuous models
\end_layout

\begin_layout Author
Jae S.
 Choi
\end_layout

\begin_layout Institution
Population Ecology Division, Fisheries and Oceans Canada, Bedford Institute
 of Oceanography
\end_layout

\begin_layout Address
1 Challenger Drive, Dartmouth, Nova Scotia, Canada
\end_layout

\begin_layout Standard
Version date: 30/08/2019
\end_layout

\begin_layout Abstract
An examination of continuous models of spatiotemporal variability in a fisheries
 oceanography context and examples of use.
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
Ecological and biological processes demonstrate variability in space and
 in time.
 Characterizing this variability is necessary to understand the generative
 processes.
 Sampling design tries to approach such issues by trying to balance information
 obtained vs costs of sampling.
 Strategies can range from completely random sampling in the absence of
 additional information, to some form of stratified random that choose samples
 from strata constrained by factors believed to be pertinent or informative
 or even blocked designs that attempt to abstract away such unmeasured factors
 as 
\begin_inset Quotes qld
\end_inset

background variability
\begin_inset Quotes qrd
\end_inset

.
 A common one is of course areal stratification based upon some prior knowledge
 that is known or believed to be informative (e.g., depth, temperature or
 some oceanic feature), such that the variability within strata will be
 smaller than that between strata.
 The lower the variability within strata (relative to between-strata variability
), the 
\begin_inset Quotes qld
\end_inset

better
\begin_inset Quotes qrd
\end_inset

 the stratification of spatial areas (
\begin_inset Quotes qld
\end_inset

design
\begin_inset Quotes qrd
\end_inset

) has captured local homogeneities in the process of interest (e.g., abundance
 of some organism); that is, each sample is thought to be more representative
 of the stratum that it represents.
\end_layout

\begin_layout Standard
The problem of course is that the size of these strata can shrink to unmanageabl
e numbers as the number of informative factors increase and the kinds of
 processes also increase.
 Further, the locations of such strata can shift if they are based upon
 features that are not geographically fixed, such as with temperature, oxygen
 levels, abundance of prey or predators, light levels, etc.
 The fixed area approach, therefore, crudely 
\begin_inset Quotes qld
\end_inset

adjusts
\begin_inset Quotes qrd
\end_inset

 for the influence of these 
\begin_inset Quotes qld
\end_inset

extraneous
\begin_inset Quotes qrd
\end_inset

 dynamic factors by representing them by crude weights such that they can,
 thereafter, be ignored.
 These dynamic factors, are however, generally informative and ignoring
 them for the sake of simplicity by 
\begin_inset Quotes qld
\end_inset

factoring them out
\begin_inset Quotes qrd
\end_inset

 can lead to bias and erroneous conclusions about the focal process(es)
 of interest.
\end_layout

\begin_layout Standard
There exist two main approaches attempting to incorporate such additional
 spatial information: (1) a spatially continuous process and (2) spatially
 aggregated areal units.
 Both approaches decompose the spatial patterns into those that are associated
 with 1) informative factors; 2) structured spatial autocorrelation patterns;
 and 3) completely nonspatial, unstructured errors.
 In the following, we will summarize the general background to the field,
 and focus upon the spatially continuous case, following closely Banerjee
 et al.'s (2004) exposition.
 To assist in the context of stock assessment and general spatial and spatiotemp
oral modeling of potentially large areas, some of these methods have been
 formulated in an R-package, 
\begin_inset Quotes qld
\end_inset


\series bold
stmv
\series default

\begin_inset Quotes qrd
\end_inset

 (https://github.com/jae0/stmv).
 This document will also serve to document these methods.
 The spatially aggregated case is treated in a separate document (https://github.
com/jae0/carstm/blob/master/docs/carstm_methods.pdf).
\end_layout

\begin_layout Section
Continuous representation
\end_layout

\begin_layout Subsection
Spatial autocorrelation
\end_layout

\begin_layout Standard
To be precise, we focus upon any spatially referenced observation 
\begin_inset Formula $Y_{s}$
\end_inset

 at locations
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
 
\begin_inset Formula $s$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
, measured in a coordinate space whose domain 
\begin_inset Formula $D$
\end_inset

 has dimensionality 
\begin_inset Formula $d$
\end_inset

 such that
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
 
\begin_inset Formula $\{\mathbf{\text{s}}\in D\in\Re^{d}\}$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
.
 We focus upon the simple case of 
\begin_inset Formula $d=2$
\end_inset

 spatial dimensions, such that for example, 
\begin_inset Formula $s=(\text{northing, easting})$
\end_inset

.
 The observations 
\begin_inset Formula $Y_{s}$
\end_inset

 are assumed to be realizations of a
\series bold
 spatial stochastic process
\series default
, 
\begin_inset Formula $y$
\end_inset

, that is some latent unobservable but real, stochastic, generative
\series bold
 function
\series default
 (i.e., a spatial random field) such that 
\begin_inset Formula $y_{s}\rightarrow Y_{s}$
\end_inset

 at {
\begin_inset Formula $k=1,\dots,K$
\end_inset

} spatial locations.
 The manner in which the variability of 
\begin_inset Formula $y_{s}$
\end_inset

 changes as a function of distance, 
\begin_inset Formula $h=\parallel s-s'\parallel$
\end_inset

, is known as the spatial autocorrelation function 
\begin_inset Formula $\rho(h)$
\end_inset

.
 The 
\begin_inset Formula $\parallel\cdot\parallel$
\end_inset

 indicates a spatial norm which in 
\begin_inset Formula $d=2$
\end_inset

 spatial dimensions is simply the Euclidean distance, 
\begin_inset Formula $h=(\Delta\text{northing}^{2}+\Delta\text{easting}^{2})^{1/2}$
\end_inset

.
\end_layout

\begin_layout Standard
The spatial model is expressed as a regression model of a stochastic process
 (Banerjee et al.
 2004):
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
g(Y_{s})=\boldsymbol{x}_{s}^{T}\boldsymbol{\boldsymbol{\beta}}+\omega_{s}+\varepsilon_{s},\label{eq:basic_spatial_model}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
where, the observations 
\begin_inset Formula $Y_{s}$
\end_inset

 are realizations of some mean process 
\begin_inset Formula $\boldsymbol{x}_{s}^{T}\boldsymbol{\boldsymbol{\beta}}$
\end_inset

 (sometimes referred to as 
\begin_inset Quotes qld
\end_inset

external drift
\begin_inset Quotes qrd
\end_inset

 in the kriging literature), and a residual error process 
\begin_inset Formula $(\omega_{s}+\varepsilon_{s})$
\end_inset

, operating potentially under the context of Generalized Linear Models via
 the link function 
\begin_inset Formula $g(\cdot)$
\end_inset

.
 The 
\begin_inset Formula $x_{s}$
\end_inset

 are spatially referenced predictors with associated parameters
\series bold
 
\begin_inset Formula $\boldsymbol{\beta}$
\end_inset


\series default
.
 The residual error process is decomposed into spatially structured 
\begin_inset Formula $\omega_{s}$
\end_inset

 and spatially unstructured 
\begin_inset Formula $\varepsilon_{s}$
\end_inset

 components, both with mean of zero.
 The latter is also commonly called the 
\begin_inset Quotes eld
\end_inset

nugget
\begin_inset Quotes erd
\end_inset

 error in geostatistics and used to represent measurement and/or microscale
 variability/processes; it is usually assumed to have a Normal distribution
 and standard deviation 
\begin_inset Formula $\sigma_{\varepsilon}$
\end_inset

.
 The spatial error is assumed to follow a
\series bold
 Gaussian process
\series default
 with mean 0 and a spatial covariance function 
\begin_inset Formula $C(s,s';\theta)$
\end_inset

 that describes form of the variance of the process as a function of distance
 between data, controlled by the parameters 
\begin_inset Formula $\theta$
\end_inset

 and spatially structured standard deviation 
\begin_inset Formula $\sigma_{\omega}$
\end_inset

 (see below).
 The full model specification is, therefore:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\begin{matrix}g(Y_{s}) & = & \boldsymbol{x}_{s}^{T}\boldsymbol{\boldsymbol{\beta}}+\omega_{s}+\varepsilon_{s},\\
\varepsilon_{s} & \sim & \text{N}(0,\sigma_{\varepsilon}^{2}),\\
\omega_{s} & \sim & \text{GP}(\boldsymbol{0},C(s,s';\theta)).
\end{matrix}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
The above is equivalent to assuming a Multivariate Normal likelihood for
 the observations 
\begin_inset Formula $\mathbf{Y}=(Y_{s_{1}},\ldots,Y_{s_{K}})^{T}$
\end_inset

, with mean 
\begin_inset Formula $\boldsymbol{\mu}=g(\mathbf{Y})=\left[x_{\text{s}_{i}}^{T}\right]_{i=1}^{K}\boldsymbol{\beta}$
\end_inset

 and a covariance matrix 
\begin_inset Formula $\boldsymbol{\mathbf{\Sigma}}=\left[C(\text{s}_{i},\text{s}_{j};\theta)\right]_{i,j=1}^{K}+\tau^{2}I_{K}$
\end_inset

, such that 
\begin_inset Formula $\mathbf{Y}\sim\text{MVN}(\boldsymbol{\mu},\boldsymbol{\Sigma})$
\end_inset

; with 
\begin_inset Formula $I_{K}$
\end_inset

 an identity matrix of size 
\begin_inset Formula $K$
\end_inset

.
 It is also computationally more efficient as fewer likelihood evaluations
 are conducted, and faster sparse-matrix implementations of the Multivariate
 Normal exist.
\end_layout

\begin_layout Standard
The spatial covariance function 
\begin_inset Formula $C(h)=C(s,s';\theta)$
\end_inset

 expresses the tendency of observations closer together to be more similar
 to each other than those further away.
 Commonly used forms include:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\begin{matrix}C(h)_{\text{Spherical}} & = & \left\{ \begin{matrix}\sigma_{s}^{2}(1-\frac{3}{2}h/\phi+\frac{1}{2}(h/\phi)^{3}); & 0<h<=\phi\\
0; & h>\phi,
\end{matrix}\right.\\
C(h)_{\text{Exponential}} & = & \sigma_{s}^{2}e^{-h/\phi},\\
C(h)_{\text{Gaussian}} & = & \sigma_{s}^{2}e^{-(h/\phi)^{2}},\\
C(h)_{\text{Powered exponential}} & = & \sigma_{s}^{2}e^{-|h/\phi|^{p}},\\
C(h)_{\text{Matérn}} & = & \sigma_{s}^{2}\frac{1}{2^{\nu-1}\Gamma(\nu)}(\sqrt{2\nu}h/\phi)^{\nu}\ K_{\nu}(\sqrt{2\nu}h/\phi).
\end{matrix}\label{eq:covar_funcs}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
At zero distance, 
\begin_inset Formula $C(0)=\text{Cov}(Y_{s},Y_{s})=\text{Var}(Y_{s})=\sigma_{\varepsilon}^{2}+\sigma_{s}^{2}$
\end_inset

 (
\emph on
i.e.
\emph default
, global spatial variance), where 
\begin_inset Formula $\sigma_{\varepsilon}$
\end_inset

 is the nonspatial, unstructured error,
\begin_inset Formula $\sigma_{s}$
\end_inset

 is the spatially structured error, and 
\begin_inset Formula $\theta=\{\phi,\nu,p,\ldots\}$
\end_inset

 are function-specific parameters including 
\begin_inset Formula $\phi$
\end_inset

 the
\emph on
 range
\emph default
 parameter.
 
\begin_inset Formula $\Gamma(\cdot)$
\end_inset

 is the Gamma function and 
\begin_inset Formula $K_{\nu}(\cdot)$
\end_inset

 is the Bessel function of the second kind with smoothness 
\begin_inset Formula $\nu$
\end_inset

.
 The Matérn covariance function is frequently used in the more recent literature
 as the shape of this function is flexible and known to be connected to
 a Gaussian spatial random process (Figure
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:autocorrelation"

\end_inset

).
\end_layout

\begin_layout Standard
\begin_inset CommandInset label
LatexCommand label
name "fig:autocorrelation"

\end_inset


\begin_inset Graphics
	filename autocorrelation.png
	lyxscale 50
	scale 10

\end_inset


\end_layout

\begin_layout Standard
Figure
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:autocorrelation"

\end_inset

: Matérn autocorrelation function, 
\begin_inset Formula $\rho(h)=C(h)/C(0)$
\end_inset

, the covariance function 
\begin_inset Formula $C(h)$
\end_inset

 scaled by the total variance 
\begin_inset Formula $C(0)$
\end_inset

, for two values of 
\begin_inset Formula $\nu$
\end_inset

 (dark lines).
 As 
\begin_inset Formula $\nu$
\end_inset

 increases 
\begin_inset Formula $(\nu=100)$
\end_inset

, it approaches the Gaussian curve (upper dark curve on the left side) while
 at smaller values 
\begin_inset Formula $(\nu=0.5)$
\end_inset

 the curve is exponential (lower dark curve on the left side).
 This flexibility has made it a popular choice in geostatistics.
 The associated semivariograms (scaled to unit variance) 
\begin_inset Formula $\gamma(h)$
\end_inset

 are shown in light stippled lines.
 Spatial scale is defined heuristically as the distance
\begin_inset Formula $h$
\end_inset

 at which the autocorrelation falls to 0.1 (dashed horizontal line) – in
 this example between 2.5 and 3 distance units, depending upon value of
\begin_inset Formula $\nu$
\end_inset

.
 The semivariance (also called 
\begin_inset Quotes qld
\end_inset

semivariogram
\begin_inset Quotes qrd
\end_inset

), 
\begin_inset Formula $\gamma(h)$
\end_inset

, is more commonly used in the kriging literature, and is simply the covariance
 function 
\begin_inset Formula $C(h)$
\end_inset

 reflected on the horizontal axis of the global variance 
\begin_inset Formula $C(0)$
\end_inset

 such that 
\begin_inset Formula $\gamma(h)=C(0)-C(h)=\frac{1}{2}\ \text{Var}[Y_{s}-Y_{s}']=\sigma_{\omega}^{2}[1-\rho(h)]$
\end_inset

.
\end_layout

\begin_layout LyX-Code
\begin_inset Note Note
status open

\begin_layout LyX-Code
#------------------ ## plot of matern covariance
\end_layout

\begin_layout LyX-Code
phi = 1
\end_layout

\begin_layout LyX-Code
sigma = 1
\end_layout

\begin_layout LyX-Code
nu = 0.5
\end_layout

\begin_layout LyX-Code
x = seq(0, 4, by=0.1)
\end_layout

\begin_layout LyX-Code
matern.covariance = function( sigma, nu, phi, x) {
\end_layout

\begin_layout LyX-Code
  1/(2^(nu-1)*gamma(nu) )
\end_layout

\begin_layout LyX-Code
  * (sqrt(2*nu)*x/phi)^nu * besselK(sqrt(2*nu)*x/phi, nu)
\end_layout

\begin_layout LyX-Code
}
\end_layout

\begin_layout LyX-Code
y = matern.covariance( sigma, nu, phi, x)
\end_layout

\begin_layout LyX-Code
plot( y~x, type="l", ylim=c(0,1.1) )
\end_layout

\begin_layout LyX-Code
nu = 100 y100 = matern.covariance( sigma, nu, phi, x)
\end_layout

\begin_layout LyX-Code
lines( x,y100 )
\end_layout

\begin_layout LyX-Code
text ( 0.3*max(x), 0.9, "nu=100 ~ Gaussian" )
\end_layout

\begin_layout LyX-Code
text ( 0.2*max(x), 0.2, "nu=0.5 ~ Exponential" )
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
Defining the spatial scale of observations is imperative for the development
 of any ecological assessment or monitoring.
 The
\series bold
 spatial autocorrelation function
\series default
 is defined as the covariance function scaled by the global variance: 
\begin_inset Formula $\rho(h)=C(h)/C(0)$
\end_inset

.
 Heuristically, the
\series bold
 spatial autocorrelation scale
\series default
 is defined as the distance at which the spatial autocorrelation decreases
 asymptotically to some low level.
 In this document, we use 
\begin_inset Formula $\rho(x)\rightarrow0.1$
\end_inset

, which may be called the 
\begin_inset Quotes qld
\end_inset

practical spatial range
\begin_inset Quotes qrd
\end_inset

 where spatial autocorrelation approaches 
\begin_inset Formula $0.1$
\end_inset

.
 This spatial scale is informative.
 When the practical spatial range is small, this means short-range processes
 dominate (relative to the scale of the whole domain).
 Thus, monitoring these processes can be meaningful and fruitful in discriminati
ng what is structuring an area of interest.
 Examples of such processes might include spatial variability in the abundance
 of less mobile, weakly dispersing species living in low currents conditions
 that create greater spatial heterogeneity.
 If, however, long-ranging processes dominate, there is a lower likelihood
 that monitoring such processes will provide insights to the internal structure
 of the area of interest.
 Examples of the latter might include higher mobility species or or organisms
 that live in high dispersal processes/currents that cause stronger spatial
 connectivity and overall greater spatial homogeneities.
 
\end_layout

\begin_layout Standard
This is perhaps clearest when spatial scale is studied in the context of
 specific organisms.
 For example, when a spatial feature (e.g., abundance distribution in space)
 demonstrates short characteristic spatial scales (i.e., a lot of spatial
 variability at smaller scales), sampling approaches must respect this and
 similarly operate at such shorter scales or even smaller if one is to be
 able to resolve the patterns and describe properly the subject of interest.
 Similarly, if a spatial feature is long-ranged and one wishes to resolve
 the patterns properly, then a sampling protocol must be similarly long-ranged
 to resolve the pattern.
 A sampling program much smaller than the characteristic spatial scale would
 be beneficial, but the accrued benefits relative to cost of sampling would
 diminish rapidly, in that time, effort and resources requirements generally
 increase more rapidly than any benefit (e.g., in the simplest case, if one
 is looking only naively at standard error as a measure of benefit, then
 it would increase asymptotically with increased effort with a power of
 
\begin_inset Formula $-1/2$
\end_inset

).
\end_layout

\begin_layout Subsection
Temporal autocorrelation
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
 see https://onlinecourses.science.psu.edu/stat510 for a nice summary
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Ecological systems also exist in a temporal frame.
 As such, similar to the above spatial considerations, there also exists
 some characteristic temporal scale upon which the processes internal to
 an area of interest and time period of interest, operate.
 The canonical example is how some quantity changes from one discrete-time
 period to another.
 This discrete-time notion of temporal autocorrelation is the slope parameter
 from a plot of a variable as a function of itself with an offset of one
 time unit:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\upsilon_{t+1}=\rho\upsilon_{t}+\eta_{t},
\]

\end_inset


\end_layout

\begin_layout Standard
with 
\begin_inset Formula $\eta_{t}\sim N(0,\sigma_{t}^{2})$
\end_inset

 and a temporal (linear) autocorrelation parameter 
\begin_inset Formula $\rho$
\end_inset

.
 This is known as an AR(1) process, where the 1 indicates 1 unit time lag.
 More complex models with moving averages and additional time-lags can also
 be specified.
 Collectively these are known as AR, ARMA, and ARIMA models.
 The difficulty with these autocorrelation timeseries formulations is the
 requirement of a complete data series without missing data.
\end_layout

\begin_layout Standard
In a completely identical approach to the spatial case, a temporal autocorrelati
on function can be used to describe the form of the temporal autocorrelation
 pattern.
 More specifically, we define a
\series bold
 temporal stochastic process
\series default
, 
\begin_inset Formula $y_{t}$
\end_inset

, that is, some latent, unobservable but real, stochastic, 
\series bold
function
\series default
 that generates observations 
\begin_inset Formula $y_{t}\rightarrow Y_{t}$
\end_inset

, where 
\begin_inset Formula $Y_{t}$
\end_inset

 are any temporally referenced observation at some time 
\begin_inset Formula $t$
\end_inset

, measured in a coordinate space whose domain 
\begin_inset Formula $D$
\end_inset

 has dimensionality 1 such that
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
 
\begin_inset Formula $\{t\in D\in\Re\}$
\end_inset

 with
\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
 
\begin_inset Formula $\{l=1,\dots,L\}$
\end_inset

 temporal 
\begin_inset Quotes qld
\end_inset

locations
\begin_inset Quotes qrd
\end_inset

.
 The manner in which the variability of 
\begin_inset Formula $Y_{t}$
\end_inset

 changes as a function of the norm (distance), 
\begin_inset Formula $h=\parallel t-t'\parallel$
\end_inset

, is the temporal autocorrelation function 
\begin_inset Formula $\rho(h)$
\end_inset

.
 The latter can take any form including the same as the spatial autocorrelation
 functions.
 The model formulation is identical to the spatial case:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\begin{matrix}g(Y_{t}) & = & \boldsymbol{x}_{t}^{T}\boldsymbol{\beta}+\omega_{t}+\varepsilon_{t},\\
\varepsilon_{t} & \sim & \text{N}(0,\sigma_{\varepsilon}^{2}),\\
\omega_{t} & \sim & \text{GP}(\boldsymbol{0},C(t,t';\theta)).
\end{matrix}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
The covariance function, for example, when expressed as an exponential decay
 model controlled by time range parameter
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
 
\begin_inset Formula $\phi_{t}$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
 is:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
C(t,t';\theta_{t})=\sigma_{t}^{2}e^{-|h|/\phi_{t}}.
\]

\end_inset


\end_layout

\begin_layout Standard
At zero time difference, 
\begin_inset Formula $C(0)=\text{Cov}(Y_{t},Y_{t})=\text{Var}(Y_{t})=\sigma_{\varepsilon}^{2}+\sigma_{t}^{2}$
\end_inset

 (
\emph on
i.e.
\emph default
, global temporal variance), where 
\begin_inset Formula $\sigma_{\varepsilon}$
\end_inset

 is the nonspatial, unstructured error, 
\begin_inset Formula $\sigma_{t}$
\end_inset

 is the temporally structured error.
 The 
\series bold
temporal autocorrelation function
\series default
 is defined as the covariance function scaled by the global variance: 
\begin_inset Formula $\rho_{t}(h)=C(h)/C(0)$
\end_inset

.
 Heuristically, the
\series bold
 temporal autocorrelation scale
\series default
 is defined as the time difference at which the temporal autocorrelation
 decreases asymptotically to some low level.
 In this document, we will use the same threshold as the 
\begin_inset Quotes qld
\end_inset

practical spatial range
\begin_inset Quotes qrd
\end_inset

, 
\begin_inset Formula $\rho_{t}(x)\rightarrow0.1$
\end_inset

, and refer to it as the 
\begin_inset Quotes qld
\end_inset

practical temporal range
\begin_inset Quotes qrd
\end_inset

 at which temporal autocorrelation approaches 0.1.
 
\end_layout

\begin_layout Standard
Similar to the case of spatial scales, temporal scales also have a simple
 implication in terms of monitoring and assessment.
 Short time-range variations require higher sampling effort to resolve/understan
d the issues and vice-versa.
 If resolving short-term processes is a study's goal, then sampling must
 also necessarily be more frequent.
 However, similar to spatial scale issues, there is a point where there
 will be diminishing returns for any increase in the resolution of a temporal
 signal.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Subsubsection
(Aside) Background:
\end_layout

\begin_layout Plain Layout
(copied from https://onlinecourses.science.psu.edu/stat510/node/80)
\end_layout

\begin_layout Plain Layout
The autocovariance and spectral density are Fourier transform pairs.
 We won’t worry about the calculus of the situation.
 We’ll focus on the estimation of the spectral density – the frequency domain
 characterization of a series.
 The Fourier transform equations are only given here to establish that there
 is a direct link between the time domain representation and the frequency
 domain representation of a series.
\end_layout

\begin_layout Plain Layout
Mathematically, the spectral density is defined for both negative and positive
 frequencies.
 However, due to symmetry of the function and its repeating pattern for
 frequencies outside the range -1/2 to +1/2, we only need to be concerned
 with frequencies between 0 and +1/2.
\end_layout

\begin_layout Plain Layout
The  "total” integrated spectral density equals the variance of the series.
 Thus the spectral density within a particular interval of frequencies can
 be viewed as the amount of the variance explained by those frequencies.
\end_layout

\begin_layout Plain Layout
Methods for Estimating the Spectral Density
\end_layout

\begin_layout Plain Layout
The raw periodogram is a rough sample estimate of the population spectral
 density.
 The estimate is  "rough”, in part, because we only use the discrete fundamental
 harmonic frequencies for the periodogram whereas the spectral density is
 defined over a continuum of frequencies.
\end_layout

\begin_layout Plain Layout
One possible improvement to the periodogram estimate of the spectral density
 is to smooth it using centered moving averages.
 An additional  "smoothing” can be created using tapering methods which
 weight the ends (in time) of the series less than the center of the data.
 We’ll not cover tapering in this lesson.
 Interested parties can see Section 4.5 in the book and various Internet
 sources.
\end_layout

\begin_layout Plain Layout
An alternative approach to smoothing the periodogram is a parametric estimation
 approach based on the fact that any stationary time series can be approximated
 by an AR model of some order (although it might be a high order).
 In this approach a suitable AR model is found, and then the spectral density
 is estimated as the spectral density for that estimated AR model.
\end_layout

\begin_layout Plain Layout
Smoothing Method (Nonparametric Estimation of the Spectral Density)
\end_layout

\begin_layout Plain Layout
The usual method for smoothing a periodogram has such a fancy name that
 it sounds difficult.
 In fact, it’s merely a centered moving average procedure with a few possible
 modifications.
 For a time series, the Daniell kernel with parameter m is a centered moving
 average which creates a smoothed value at time t by averaging all values
 between times t – m and t +m (inclusive).
 For example, the smoothing formula for a Daniell kernel with m = 2 is
\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\[
\hat{x}_{t}=\frac{x_{t-2}+x_{t-1}+x_{t}+x_{t+1}+x_{t+2}}{5}
\]

\end_inset


\end_layout

\begin_layout Plain Layout
In R, the weighting coefficients for a Daniell kernel with m = 2 can be
 generated with the command kernel("daniell", 2).
 The result is
\end_layout

\begin_layout Plain Layout
coef[-2] = 0.2 coef[-1] = 0.2 coef[ 0] = 0.2 coef[ 1] = 0.2 coef[ 2] = 0.2
\end_layout

\begin_layout Plain Layout
The subscripts for coef [ ] refer to the time difference from the center
 of the average at time t.
 Thus the smoothing formula in this instance is
\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\[
\hat{x}_{t}=0.2x_{t-2}+0.2x_{t-1}+0.2x_{t}+0.2x_{t+1}+0.2x_{t+2},
\]

\end_inset


\end_layout

\begin_layout Plain Layout
which is the same as the formula given above.
\end_layout

\begin_layout Plain Layout
The modified Daniell kernel is such that the two endpoints in the averaging
 receive half the weight that the interior points do.
 For a modified Daniell kernel with m = 2, the smoothing is
\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\[
\hat{x}_{t}=\frac{x_{t-2}+2x_{t-1}+2x_{t}+2x_{t+1}+x_{t+2}}{8}=0.125x_{t-2}+0.25x_{t-1}+0.25x_{t}+0.25x_{t+1}+0.125x_{t+2}
\]

\end_inset


\end_layout

\begin_layout Plain Layout
In R, the command kernel("modified.daniell", 2) will list the weighting coefficie
nts just used.
\end_layout

\begin_layout Plain Layout
Either the Daniell kernel or the modified Daniell kernel can be convoluted
 (repeated) so that the smoothing is applied again to the smoothed values.
 This produces a more extensive smoothing by averaging over a wider time
 interval.
 For instance, to repeat a Daniell kernel with m = 2 on the smoothed values
 that resulted from a Daniell kernel with m = 2, the formula would be
\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\[
\hat{\hat{x}}_{t}=\frac{\hat{x}_{t-2}+\hat{x}_{t-1}+\hat{x}_{t}+\hat{x}_{t+1}+\hat{x}_{t+2}}{5}
\]

\end_inset


\end_layout

\begin_layout Plain Layout
This is the average of the smoothed values within two time periods of time
 t, in either direction.
\end_layout

\begin_layout Plain Layout
In R, the command kernel("daniell",c(2,2)) will supply the coefficients
 that would be applied to as weights in averaging the original data values
 for a convoluted Daniell kernel with m = 2 in both smoothings.
 The result is
\end_layout

\begin_layout Plain Layout
> kernel ("daniell",c(2,2))
\end_layout

\begin_layout Plain Layout
coef[-4] = 0.04 coef[-3] = 0.08 coef[-2] = 0.12 coef[-1] = 0.16 coef[ 0] = 0.20
 coef[ 1] = 0.16 coef[ 2] = 0.12 coef[ 3] = 0.08 coef[ 4] = 0.04
\end_layout

\begin_layout Plain Layout
This generates the smoothing formula
\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\[
\hat{x}_{t}=0.04x_{t-4}+0.08x_{t-3}+0.12x_{t-2}+0.16x_{t-1}+0.20x_{t}+0.16x_{t+1}+0.12x_{t+2}+0.08x_{t+3}+0.04x_{t+4}.
\]

\end_inset


\end_layout

\begin_layout Plain Layout
A convolution of the modified method in which the end points have less weight
 is also possible.
 The command
\end_layout

\begin_layout Plain Layout
kernel("modified.daniell",c(2,2)) gives these coefficients:
\end_layout

\begin_layout Plain Layout
coef[-4] = 0.01563 coef[-3] = 0.06250 coef[-2] = 0.12500 coef[-1] = 0.18750
 coef[ 0] = 0.21875 coef[ 1] = 0.18750 coef[ 2] = 0.12500 coef[ 3] = 0.06250
 coef[ 4] = 0.01563
\end_layout

\begin_layout Plain Layout
Thus the center values are weighted slightly more heavily than in the unmodified
 Daniell kernel.
\end_layout

\begin_layout Plain Layout
When we smooth a periodogram, we are smoothing across a frequency interval
 rather than a time interval.
 Remember that the periodogram is determined at the fundamental frequencies
\begin_inset Formula $\omega_{j}=j/n$
\end_inset

 for
\begin_inset Formula $j=1,2,\cdots,n/2$
\end_inset

.
 Let
\begin_inset Formula $I(\omega_{j})$
\end_inset

 denote the periodogram value at frequency
\begin_inset Formula $\omega_{j}=j/n$
\end_inset

.
 When we use a Daniell kernel with parameter m to smooth a periodogram,
 the smoothed value
\begin_inset Formula $\hat{I}(\omega_{j})$
\end_inset

 is a weighted average of periodogram values for frequencies in the range
\begin_inset Formula $(j-m)/n$
\end_inset

 to
\begin_inset Formula $(j+m)/n$
\end_inset

.
\end_layout

\begin_layout Subsubsection
Bandwidth
\end_layout

\begin_layout Plain Layout
There are
\begin_inset Formula $L=2m+1$
\end_inset

 fundamental frequency values in the range
\begin_inset Formula $(j-m)/n$
\end_inset

 to
\begin_inset Formula $(j+m)/n$
\end_inset

, the range of values used for smoothing.
 The bandwidth for the smoothed periodogram is defined as
\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\[
B_{\omega}=\frac{L}{n}
\]

\end_inset


\end_layout

\begin_layout Plain Layout
The bandwidth is a measure of the width of the frequency interval(s) used
 for smoothing the periodogram.
\end_layout

\begin_layout Plain Layout
When unequal weights are used in the smoothing, the bandwidth definition
 is modified.
 Denote the smoothed periodogram value at
\begin_inset Formula $\omega_{j}=j/n$
\end_inset

 as
\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\[
\hat{I}(\omega_{j})=\sum_{k=-m}^{+m}h_{k}I\left(\omega_{j}+\frac{k}{n}\right).
\]

\end_inset


\end_layout

\begin_layout Plain Layout
The
\begin_inset Formula $h_{k}$
\end_inset

 are the possibly unequal weights used in the smoothing.
 The bandwidth formula is then modified to
\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\[
B_{\omega}=\frac{L_{h}}{n}=\frac{1/\sum h_{k}^{2}}{n}
\]

\end_inset


\end_layout

\begin_layout Plain Layout
Actually, this formula works for equal weights too.
\end_layout

\begin_layout Plain Layout
The bandwidth should be sufficient to smooth our estimate, but if we use
 a bandwidth that is too great, we’ll smooth out the periodogram too much
 and miss seeing important peaks.
 In practice, it usually takes some experimentation to find the bandwidth
 that gives a suitable smoothing.
\end_layout

\begin_layout Plain Layout
The bandwidth is predominately controlled by the number of values that are
 averaged in the smoothing.
 In other words, the m parameter for the Daniell kernel and whether the
 kernel is convoluted (repeated) affect the bandwidth.
\end_layout

\begin_layout Plain Layout
Note: The bandwidths R reports with its plots don’t match the values that
 would be calculated using the formulas above.
 Please see the footnote on p.
 197 of your text for an explanation.
\end_layout

\begin_layout Plain Layout
R Code
\end_layout

\begin_layout Plain Layout
Averaging/smoothing the periodogram with a Daniell kernel can be accomplished
 in R using a sequence of two commands.
 The first defines a Daniell kernel and the second creates the smoothed
 periodogram.
\end_layout

\begin_layout Plain Layout
As an example, suppose that the observed series is named x and we wish to
 smooth the periodogram using a Daniell kernel with m = 4.
 The commands are
\end_layout

\begin_layout Plain Layout
k = kernel("daniell", 4)
\end_layout

\begin_layout Plain Layout
spec.pgram(x, k, taper=0, log = "no")
\end_layout

\begin_layout Plain Layout
The first command creates the weighting coefficients needed for the smoothing
 and stores them in a vector named k.
 (It’s arbitrary to call it k.
 It could be called anything.) The second command asks for a spectral density
 estimate based on the periodogram for the series x, using the weighting
 coefficients stored in k, with no taper, and the plot will be on an ordinary
 scale, not a log scale.
\end_layout

\begin_layout Plain Layout
If a convolution is desired, the kernel command could be modified to something
 like k = kernel("daniell", c(4,4)).
\end_layout

\begin_layout Plain Layout
There are two possible ways to achieve a modified Daniell kernel.
 You can either change the kernel command to refer to the  "modified.daniell”
 rather than  "daniell” or you can skip using the kernel command and use
 a spans parameter in the spec.pgram command.
\end_layout

\begin_layout Plain Layout
The spans parameter gives the length (=2m+1) of the desired modified Daniell
 kernel.
 For instance, a modified Daniell kernel with m = 4 has length L = 2m+1
 = 9 so the we could use the command
\end_layout

\begin_layout Plain Layout
spec.pgram(x, spans=9, taper = 0, log="no")
\end_layout

\begin_layout Plain Layout
Two passes of a modified Daniell kernel with m = 4 on each pass can be done
 using
\end_layout

\begin_layout Plain Layout
spec.pgram(x, spans=c(9,9), taper = 0, log="no")
\end_layout

\begin_layout Plain Layout
Example: This example will use the fish recruitment series that’s used in
 several places in the text, including several places in chapter 4.
 The series consists of n = 453 monthly values of a measure of a fish population
 in a southern hemisphere location.
 The data are in the file recruit.dat.
\end_layout

\begin_layout Plain Layout
The raw periodogram can be created using the command (or it could be created
 using the method given in Lesson 6).
\end_layout

\begin_layout Plain Layout
spec.pgram(x, taper=0, log="no")
\end_layout

\begin_layout Plain Layout
Note that in the command just given we have omitted the parameter that gives
 weights for smoothing.
\end_layout

\begin_layout Plain Layout
The raw periodogram follows:
\end_layout

\begin_layout Plain Layout
graph
\end_layout

\begin_layout Plain Layout
The next plot is a smoothed periodogram using a Daniell kernel with m =
 4.
 Note that one effect of the smoothing is that the dominant peak in the
 unsmoothed version is now the second tallest peak.
 This happened because the peak is so sharply defined in the unsmoothed
 version that when we average it with a few surrounding values the height
 is reduced.
\end_layout

\begin_layout Plain Layout
graph
\end_layout

\begin_layout Plain Layout
The next plot is a smoothed periodogram using two passes of a Daniell kernel
 with m = 4 on each pass.
 Note how it is even more smoothed than previously.
\end_layout

\begin_layout Plain Layout
graph
\end_layout

\begin_layout Plain Layout
To learn where the two dominant peaks are located, assign a name to the
 spec.pgram output and then you can list it.
 For instance,
\end_layout

\begin_layout Plain Layout
specvalues = spec.pgram(x, k, taper=0, log="no") specvalues
\end_layout

\begin_layout Plain Layout
You can sift through the output to find the frequencies at which the peaks
 occur.
 The frequencies and spectral density estimates are listed separately, but
 in the same order.
 Identify the maximum spectral densities and then find the corresponding
 frequencies.
\end_layout

\begin_layout Plain Layout
Here, the first peak is at a frequency ≈ .0229.
 The period (number of months) associated with this cycle = 1/.0229 = 43.7
 months, or about 44 months.
 The second peak occurs at a frequency ≈ 0.083333.
 The associated period = 1/.08333 = 12 months.
 The first peak is associated with an El Nino weather effect.
 The second is the usual 12 month seasonal effect.
\end_layout

\begin_layout Plain Layout
These two commands will put vertical dotted lines onto the (estimated) spectral
 density plot at the approximate locations of the peak densities.
\end_layout

\begin_layout Plain Layout
abline(v=1/44, lty="dotted") abline(v=1/12, lty = "dotted")
\end_layout

\begin_layout Plain Layout
Here’s the resulting plot:
\end_layout

\begin_layout Plain Layout
graph
\end_layout

\begin_layout Plain Layout
We’ve smoothed enough, but for demonstration purposes, the next plot is
 the result of
\end_layout

\begin_layout Plain Layout
spec.pgram(x, spans=c(13,13), taper=0, log="no")
\end_layout

\begin_layout Plain Layout
This uses two passes of a modified Daniell kernel with length L = 13 (so
 m = 6) each time.
 The plot is a bit smoother, but not by much.
 The peaks, by the way, are in exactly the same places as in the plot immediatel
y above.
\end_layout

\begin_layout Plain Layout
graph
\end_layout

\begin_layout Plain Layout
It’s definitely possible to smooth too much.
 Suppose that we were to use a modified Daniell kernel of total length =
 73 (m = 36).
 The command is
\end_layout

\begin_layout Plain Layout
spec.pgram(x, spans=73, taper=0, log="no")
\end_layout

\begin_layout Plain Layout
The result follows.
 The peaks are gone!
\end_layout

\begin_layout Plain Layout
graph
\end_layout

\begin_layout Plain Layout
Parametric Estimation of the Spectral Density
\end_layout

\begin_layout Plain Layout
The smoothing method of spectral density estimation is called a nonparametric
 method because it doesn’t use any parametric model for the underlying time
 series process.
 An alternative method is a parametric method which entails finding the
 best fitting AR model for the series and then plotting the spectral density
 of that model.
 This method is supported by a theorem which says that the spectral density
 of any time series process can be approximated by the spectral density
 of an AR model (of some order, possibly a high one).
\end_layout

\begin_layout Plain Layout
In R, parametric estimation of the spectral density is easily done with
 the command/function spec.ar.
 A command like spec.ar(x, log="no") will cause R to do all of the work.
 Again, to identify peaks we can assign a name to the spec.ar results by
 doing something like specvalues=spec.ar(x, log ="no").
\end_layout

\begin_layout Plain Layout
For the fish recruitment example, the following plot is the result.
 Note that the density plotted is that of an AR(13) model.
 We can certainly find more parsimonious ARIMA models for these data.
 We’re just using the spectral density of that model to approximate the
 spectral density of the observed series.
\end_layout

\begin_layout Plain Layout
graph
\end_layout

\begin_layout Plain Layout
The appearance of the estimated spectral density is about he same as before.
 The estimated El Nino peak is located at a slightly different place – the
 frequency is about 0.024 for a cycle of about 1/.024 = about 42 months.
\end_layout

\begin_layout Subsubsection
De-trending
\end_layout

\begin_layout Plain Layout
A series should be de-trended prior to a spectral analysis.
 A trend will cause such a dominant spectral density at a low frequency
 that other peaks won’t be seen.
 By default, the R command spec.pgram performs a de-trending using a linear
 trend model.
 That is, the spectral density is estimated using the residuals from a regressio
n done where the y-variable = observed data and the x-variable = t.
 If a different type of trend is present, a quadratic for instance, then
 a polynomial regression could be used to de-trend the data before the estimated
 spectral density is explored.
 Note, however, that the R command spec.ar, however does not perform a de-trendin
g by default.
\end_layout

\begin_layout Plain Layout
Application of Smoothers to Raw Data
\end_layout

\begin_layout Plain Layout
Note that the smoothers described here could also be applied to raw data.
 The Daniell kernel and its modifications are simply moving average (or
 weighted moving average) smoothers.
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Spatiotemporal autocorrelation
\end_layout

\begin_layout Standard
In reality, spatial and temporal patterns coexist and co-evolve.
 They are spatially and temporally correlated processes and as such a challenge
 to characterize and model properly.
 This renders the independent treatment and estimation of autocorrelation
 in time and space problematic.
 Nonetheless, new developments in computational methods are bringing such
 models within range of use.
 This is primarily due to efficient methods associated with numerical modeling
 of Stochastic Partial Differential Equations (SPDEs), and the use of spectral
 (Fourier) methods.
\end_layout

\begin_layout Standard
Again, following Banerjee et al.'s (2004) development, spatiotemporal models
 can be seen as a simple extension of the spatial regression model.
 The observations, 
\begin_inset Formula $Y_{s,t}$
\end_inset

 are measured in a coordinate space 
\begin_inset Formula $\{(s,t)\in D\in\mathfrak{R}^{d}\mathfrak{\times R^{1}}\}$
\end_inset

 in the domain 
\begin_inset Formula $D$
\end_inset

 of dimensionality 
\begin_inset Formula $d+1$
\end_inset

 with {
\begin_inset Formula $k=1,\dots,K$
\end_inset

} spatial and 
\begin_inset Formula $\{l=1,\dots,L\}$
\end_inset

 temporal locations.
 The space-time regression model can then be specified as:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
g(Y_{s,t})=\boldsymbol{x}_{s,t}^{T}\boldsymbol{\beta}_{s,t}+\omega_{s,t}+\varepsilon_{s,t},
\]

\end_inset


\end_layout

\begin_layout Standard
where, 
\begin_inset Formula $\boldsymbol{x}_{s,t}^{T}\boldsymbol{\beta}_{s,t}$
\end_inset

 is the mean process (or 
\begin_inset Quotes qld
\end_inset

external drift
\begin_inset Quotes qrd
\end_inset

 in the kriging literature) and the error process is decomposed into a spatiotem
porally structured component 
\begin_inset Formula $\omega$
\end_inset

 and an unstructured component 
\begin_inset Formula $\varepsilon$
\end_inset

, operating again under a generalized linear model framework, through the
 action of the link function 
\begin_inset Formula $g(\cdot)$
\end_inset

.
 The parameters 
\begin_inset Formula $\boldsymbol{\beta}_{s,t}$
\end_inset

 of the spatially and temporally referenced predictors 
\begin_inset Formula $\boldsymbol{x}_{s,t}$
\end_inset

 can have variable forms:
\end_layout

\begin_layout Itemize
\begin_inset Formula $\boldsymbol{\beta}$
\end_inset

 – completely fixed with no variation in time and space;
\end_layout

\begin_layout Itemize
\begin_inset Formula $\boldsymbol{\beta}_{-,t}$
\end_inset

 – temporally varying and no spatial structure;
\end_layout

\begin_layout Itemize
\begin_inset Formula $\boldsymbol{\beta}_{s,-}$
\end_inset

– spatially varying and no temporal structure;
\end_layout

\begin_layout Itemize
\begin_inset Formula $\beta_{s,-}+\beta_{-,t}$
\end_inset

 – space and time varying independently, separably additive (or multiplicative
 if on a log scale);
\end_layout

\begin_layout Itemize
\begin_inset Formula $\boldsymbol{\beta}_{s,t}$
\end_inset

– varying in both time and space complex (nonseparable) and potentially
 hierarchically (non-simply).
\end_layout

\begin_layout Standard
The
\emph on
 unstructured
\emph default
 error is usually assumed to be a Normal
\emph on
 iid
\emph default
 error process: 
\begin_inset Formula $\varepsilon_{s,t}\sim N(0,\sigma_{\varepsilon}^{2})$
\end_inset

.
 However, the manner in which the
\emph on
 spatiotemporally structured
\emph default
 error should be parameterized is not straight-forward.
 Some common approaches include:
\end_layout

\begin_layout Itemize
\begin_inset Formula $\omega_{-,t}$
\end_inset

 – temporal effects nested in sites (temporal autocorrelation at each site,
 no spatial autocorrelation);
\end_layout

\begin_layout Itemize
\begin_inset Formula $\omega_{s,-}$
\end_inset

 – spatial effects nested in time (spatial autocorrelation at each time
 slice, no temporal autocorrelation);
\end_layout

\begin_layout Itemize
\begin_inset Formula $\omega_{s,-}+\omega_{-,t}$
\end_inset

 –
\emph on
 separable
\emph default
 (spatial and temporal autocorrelations are independent and additive (or
 multiplicative if on log scale) with 
\begin_inset Formula $\omega_{-,t}\sim\text{GP}(\boldsymbol{0},C(\boldsymbol{\text{t}},\boldsymbol{\text{t}}';\theta_{t}))$
\end_inset

 and 
\begin_inset Formula $\omega_{s,-}\sim\text{GP}(\boldsymbol{0},C(\mathbf{s},\mathbf{s}';\theta_{s}))$
\end_inset

;
\end_layout

\begin_layout Itemize
\begin_inset Formula $\omega_{s,t}$
\end_inset

 – non-separable (both time and space structure evolve in a nonsimple manner).
\end_layout

\begin_layout Standard
If the spatial and temporal errors are assumed to be derived from a
\series bold
 Gaussian Process
\series default
 with mean 0 and some covariance 
\begin_inset Formula $C(\cdot,\cdot;\mathbf{\theta})$
\end_inset

, then the spatial covariance can be modeled with a flexible form such as
 the Matérn:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
C(\Delta s)_{\text{Matérn}}=\sigma_{s}^{2}\frac{1}{2^{\nu-1}\Gamma(\nu)}(\sqrt{2\nu}|\Delta s|/\phi)^{\nu}\ K_{\nu}(\sqrt{2\nu|}\Delta s|/\phi).
\]

\end_inset


\end_layout

\begin_layout Standard
Similarly, the temporal covariance can be formulated as any reasonable autocorre
lation model such as for example the exponential: 
\begin_inset Formula $C(\Delta t)_{\text{Exponential}}=\sigma_{t}^{2}e^{-|\Delta t|/\phi_{t}}$
\end_inset

.
\end_layout

\begin_layout Standard
While conceptually coherent and elegant, the evaluation of the likelihoods
 in theses models requires the repeated computation of the inverse of the
 covariance matrix 
\begin_inset Formula $\Sigma_{n\times n}$
\end_inset

 of size n, an operation that scales with 
\begin_inset Formula $\mathcal{O}(n^{3})$
\end_inset

 operations.
 This has been a bottleneck to further development and use of these covariance-b
ased methods in large scaled problems of space and space-time.
 Approximations have been suggested to overcome this computational limit:
 modeling the spatial process 
\begin_inset Formula $\omega$
\end_inset

 with a lower dimensional process via kernel convolutions, moving averages,
 low rank splines/basis functions and predictive processes (projection of
 spatial process onto a smaller subset; Sølna and Switzer 1996, Wikle and
 Cressie 1999, Hung et al.
 2004, Xu et al.
 2005, Banerjee et al.
 2004); approximating the spatial process as a Markov random field with
 Laplace and SPDE Approximations (Lindgren and Rue 2015); and approximating
 the likelihood of the spatial-temporal SPDE process with a spectral domain
 process (Sigrist et al.
 2012).
\end_layout

\begin_layout Standard
In the spatiotemporal setting, separable models are almost always used for
 the sake of computational speed as this treats space and time independently,
 reducing the problems crudely from 
\begin_inset Formula $\mathcal{O}((KL)^{3})$
\end_inset

 to 
\begin_inset Formula $\mathcal{O}(K^{3})+\mathcal{O}(L^{3})$
\end_inset

 operations; where 
\begin_inset Formula $K$
\end_inset

 is the number of spatial locations and 
\begin_inset Formula $L$
\end_inset

 the number of time slices.
 In reality, however, such separable models are usually inappropriate unless
 the study area is homogeneous and truly first and second order constant
 (i.e., constant mean, variance) across both time and space, a fact that is
 seldom true in most ecological systems (see below).
\end_layout

\begin_layout Standard
A central assumption of all spatial and spatiotemporal models is that the
 form and magnitude of the autocorrelation in space and usually also in
 time are second order stationary (constant mean and variance).
 This can be forced to be the case by modeling the mean effects and operating
 upon a residual error that is stationary.
 However, in practice, there is spatial heterogeneity of variance as well
 which cannot be easily modeled in a simple regression context.
 This is notoriously the case with biology where aggregation and behavior
 is highly clustered and context (location and time) dependent (nonlinear).
\end_layout

\begin_layout Section
Spectral representation
\end_layout

\begin_layout Standard
Fourier transforms decompose any function in a 
\begin_inset Quotes qld
\end_inset

continuous
\begin_inset Quotes qrd
\end_inset

 domain (e.g., time, space) as an infinite sum of sine and cosine functions
 (Fourier 1822).
 The sine and cosine functions are interpreted as amplitudes and phase shifts
 associated with an infinite range of frequencies in the "spectral" domain.
 Computationally efficient algorithms for Fast Fourier Transforms (FFT)
 were initially developed by Gauss in 1805 (Heideman et al.
 1985), and elaborated upon by Yates (1937), Danielson and Lanczos (1942),
 and fully generalized by Cooley and Tukey (1965).
 This enabled operations in the spectral domain that are orders of magnitude
 faster than their equivalent operations in the continuous time and/or space
 domains.
 For example, for a problem with 
\begin_inset Formula $n$
\end_inset

 data, the FFT has a computational complexity of order
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\xout off
\uuline off
\uwave off
\noun off
\color none
 
\begin_inset Formula $\mathcal{O}(n\text{\ensuremath{\cdot}log}_{2}(n))$
\end_inset

.
 In contrast, an operation of importance in the context of spatiotemporal
 modeling is 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\xout default
\uuline default
\uwave default
\noun default
\color inherit
inversion of 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\xout off
\uuline off
\uwave off
\noun off
\color none
a covariance matrix 
\begin_inset Formula $\Sigma_{n\times n}$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\xout default
\uuline default
\uwave default
\noun default
\color inherit
 that has a computational complexity of order
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\xout off
\uuline off
\uwave off
\noun off
\color none
 
\begin_inset Formula $\mathcal{O}(n^{3})$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\xout default
\uuline default
\uwave default
\noun default
\color inherit
.
 This represents an improvement by a factor of 
\begin_inset Formula $n^{2}/\text{log}_{2}(n)$
\end_inset

, which even for a simple problem with 
\begin_inset Formula $n=10^{3}$
\end_inset

 data locations, can represent up to a 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\xout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $10^{2}$
\end_inset

 fold
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\xout default
\uuline default
\uwave default
\noun default
\color inherit
 improvement in computational speed.
 Parenthetically, the Discrete Fourier Transform (DFT) has the intermediate
 computation complexity of order 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\xout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\mathcal{O}(n^{2})$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\xout default
\uuline default
\uwave default
\noun default
\color inherit
.
\end_layout

\begin_layout Standard
Beyond computational complexity, there exist two additional features of
 the Fourier Transform that are especially significant in the context of
 spatiotemporal modeling.
 The first is known as the Wiener-Khinchin (-Einstein, - Kolmogorov) theorem
 (Wiener 1930; Khintchine 1934; Robertson and George 2012), which connects
 the autocorrelation function of a stationary random process with the power
 spectral density (also known as a power spectrum) of the process.
 That is, a rapid estimation of the autocorrelation (and cross-correlation)
 of a process can be obtained from the power spectrum.
 The second aspect of significance is the 
\series bold
convolution
\series default
 theorem: the combination of two functions in the continuous domain becomes
 simple multiplication in the spectral domain.
 The convolution of an autocorrelation function with a spectral representation
 of the spatiotemporal process of interest amounts to a kernel-based smoothing
 interpolator respecting the temporal/spatial/spatiotemporal autocorrelation.
 These two aspects, respectively, permit fast and unbiased variogram representat
ions and rapid application of the variogram without having to invert and
 solve the covariance matrix 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\xout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\Sigma_{n\times n}$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\xout default
\uuline default
\uwave default
\noun default
\color inherit
.
 
\end_layout

\begin_layout Standard
In what follows, we will focus upon a one-dimensional problem for simplicity,
 with the awareness that this can be simply extended to higher dimensions,
 including space and space-time dimensions.
 Specifically, any measurements along the one dimensional 
\begin_inset Formula $d=1$
\end_inset

 coordinate space 
\begin_inset Formula $\{(x)\in D\in\mathfrak{R}^{d}\}$
\end_inset

, of domain 
\begin_inset Formula $D$
\end_inset

,
\begin_inset space \thinspace{}
\end_inset


\begin_inset space ~
\end_inset

generated from the process of interest 
\begin_inset Formula $g(x)$
\end_inset

 can be represented in the frequency domain as a series of complex trigonometric
 coefficients 
\begin_inset Formula $G(k)$
\end_inset

 and vice versa.
 The forward and backward Fourier transforms are respectively: 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
G(k)=\mathcal{F}_{x}[g(x)](k)=\int_{-\infty}^{\infty}g(x)\cdot e^{-(2\pi ki)x}\,dx,
\]

\end_inset


\begin_inset Formula 
\[
g(x)=\mathcal{F}_{k}^{-1}[G(k)](x)=\int_{-\infty}^{\infty}G(k)\cdot e^{(2\pi xi)k}\,dk.
\]

\end_inset

 
\end_layout

\begin_layout Standard
The above make use of Euler's formula, 
\begin_inset Formula $e^{2\pi\theta i}=\cos(2\pi\theta)+i\cdot\sin(2\pi\theta)$
\end_inset

, to compactly represent the amplitudes and phase shifts of the sine and
 cosine functions with amplitudes 
\begin_inset Formula $g(x)$
\end_inset

 and 
\begin_inset Formula $G(k)$
\end_inset

, also called Fourier pairs.
 The 
\begin_inset Formula $i$
\end_inset

 represent by convention, imaginary numbers.
 
\end_layout

\begin_layout Standard
In an applied setting, the discrete form of the transform is particularly
 useful as measurements are usually discrete at some fundamental level (such
 as a sampling event).
 The discrete Fourier transform and it's inverse are as follows:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
G_{k}=\mathcal{F}_{x}[g_{x}](k)=\sum_{n=0}^{N-1}g_{x}\cdot e^{-(2\pi ki)(x/N)}
\]

\end_inset


\begin_inset Formula 
\[
g_{x}=\mathcal{F}_{k}^{-1}[G_{k}](x)={\frac{1}{N}}\sum_{k=0}^{N-1}G_{k}\cdot e^{(2\pi xi)(k/N)}
\]

\end_inset


\end_layout

\begin_layout Standard
The 
\begin_inset Formula $g_{x}=\{g_{0},g_{1},\dots,g_{N-1}\}$
\end_inset

 are vector of 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\xout off
\uuline off
\uwave off
\noun off
\color none
values in time or space of the data and the 
\begin_inset Formula $G_{k}=\{G_{0},G_{1,},\dots,G_{N-1}\}$
\end_inset

 are discrete frequency bands.
 For each frequency band 
\begin_inset Formula $k$
\end_inset

, the associated amplitude is 
\begin_inset Formula $|G_{k}|/N={\sqrt{\operatorname{Re}(G_{k})^{2}+\operatorname{Im}(G_{k})^{2}}}/N$
\end_inset

 and the phase is the angle between the real and imaginary line: 
\begin_inset Formula ${\displaystyle \arg(G_{k})=\operatorname{atan2}{\big(}\operatorname{Im}(G_{k}),\operatorname{Re}(G_{k}){\big)}=-i\cdot\operatorname{ln}\left({\frac{G_{k}}{|G_{k}|}}\right).}$
\end_inset


\end_layout

\begin_layout Standard
The utility of the spectral representation is that the autocorrelation function
 
\begin_inset Formula $\rho(x)$
\end_inset

 of some 
\series bold
stationary
\series default
 function 
\begin_inset Formula $g(x)$
\end_inset

 is equivalent to the inverse Fourier transform of the power spectral distributi
on.
 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\rho(x)=\mathcal{F}_{k}^{-1}[|G(k)|^{2}](x)
\]

\end_inset


\end_layout

\begin_layout Standard
where, 
\begin_inset Formula $|G(k)|^{2}$
\end_inset

 is the modulus squared power spectral density derived from:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\mathcal{F}[g(x)*g(-x)](k)=G(k)\cdot G^{*}(k)=|G(k)|^{2}
\]

\end_inset

and the asterisk denotes a complex conjugate.
 
\end_layout

\begin_layout Standard
This relation is the result of the Wiener-Khinchin theorem (Robertson and
 George 2012).
 The autocorrelation function is, of course, directly related to the covariance
 function used in temporal, spatial and spatiotemporal interpolation methods.
 The utility is, however, not simply a matter of the significantly reduced
 computational complexity from 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\xout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\mathcal{O}(n^{3})$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\xout default
\uuline default
\uwave default
\noun default
\color inherit
 to 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\xout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\mathcal{O}(n\text{\ensuremath{\cdot}log}_{2}(n))$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\xout default
\uuline default
\uwave default
\noun default
\color inherit
.
 Variogram estimation methods generally make repeated use of data for variance
 estimation in various distance groups, causing spurious autocorrelation
 and, therefore, biased parameter estimates.
 The autocorrelation function, being derived from a spectral decomposition
 are independent and therefore parameter estimates are unbiased!
\end_layout

\begin_layout Standard
An FFT-based approach still faces the same challenges as the covariance-based
 approaches in that stationarity (first and second order) is assumed.
 Again, this is not guaranteed and so the iterative approach of identifying
 locally stationary areas as implemented in 
\series bold
stmv
\series default
 is necessary.
 Further, FFT methods require additional handling due to 
\begin_inset Quotes qld
\end_inset

missing
\begin_inset Quotes qrd
\end_inset

 data being common in most empirical applications.
 This can be handled by a locally weighted average scheme (kernel weights)
 which in the spectral domain is known as a Nadaraya-Watson kernel convolution
 smoother (see e.g., the documentation in the R-library, 
\begin_inset Quotes qld
\end_inset

fields
\begin_inset Quotes qrd
\end_inset

, Nychka et al.
 2017).
 
\end_layout

\begin_layout Section
Discrete representation
\end_layout

\begin_layout Standard
Aggregate/discrete approaches to represent spatial and temporal groupings
 or units are powerful methods that can usefully represent spatiotemporal
 processes.
 They are somewhat outside the bounds of the continuous representations
 treated by 
\series bold
stmv
\series default
.
 However, each local region of stationarity can be seen as a valid areal
 unit and so these aggregate models can operate in conjunction with 
\series bold
stmv
\series default
 to develop more refined lattice based representations and models, in particular
, Conditional AutoRegressive (CAR) Models.
 Alternatively, as the size of an areal unit shrinks to a smaller and smaller
 area, they can also be seen as representing some "nugget"-level (observation-le
vel or local-process) variability of some larger continuous process.
 This latter perspective was used initially to develop and justify CAR models.
 We leave this development and discussion for a separate document (Choi,
 J.S., Conditional autoregressive space-time models.
 In prep: https://github.com/jae0/carstm/blob/master/docs/carstm_methods.pdf).
\end_layout

\begin_layout Section
Spatiotemporal models of variability (stmv)
\end_layout

\begin_layout Standard
In
\series bold
 stmv
\series default
, this
\series bold
 nonstationarity
\series default
 and
\series bold
 nonseparability
\series default
 of spatial and temporal structure and associated issues of computational
 speed and complexity is addressed by formulating a simple, operational
 approach to the overall spatiotemporal problem.
 This is done by reducing the problem into small manageable subdomains where
 assumptions of stationary are valid and modeling of spatiotemporal processes
 and associated parameters become computationally feasible and supported
 by data in the subdomain.
 There is, therefore, some conceptual similarity of this approach to 
\begin_inset Quotes qld
\end_inset

geographically weighted regression
\begin_inset Quotes qrd
\end_inset

 (e.g., Fotheringham et al.
 2002) in that each subdomain can have their own model parameters, 
\begin_inset Formula $\beta_{s,t}$
\end_inset

.
 However, geographically weighted regression permit only the model parameters
 
\begin_inset Formula $\beta_{s,t}$
\end_inset

 to vary; in contrast,
\series bold
 stmv
\series default
 permits both the model parameters 
\begin_inset Formula $\beta_{s,t}$
\end_inset

 and the spatiotemporal error's model parameters 
\begin_inset Formula $\varphi_{s,t}$
\end_inset

 to vary.
\end_layout

\begin_layout Standard
To be more precise, in the spatiotemporal domain 
\begin_inset Formula $D$
\end_inset

, where 
\begin_inset Formula $\{(s,t)\in D\in\mathfrak{R}^{d}\times\mathfrak{R}^{1}|d=2\}$
\end_inset

 defines the coordinate space, we define statistical nodes
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\xout off
\uuline off
\uwave off
\noun off
\color none
 
\begin_inset Formula $\{N_{m=(1,\dots,M)}|m\in\mathfrak{R}^{d}\}$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\xout default
\uuline default
\uwave default
\noun default
\color inherit
 in a spatial lattice (or conceivably as centroids of a spatial or spatio-tempor
al mesh, though this is not yet implemented; Figure 5.1).
 The norm (distance) of data from each node is 
\begin_inset Formula $h_{m}=||s_{m},s_{Y}||$
\end_inset

.
 A local subdomain of a given node 
\begin_inset Formula $m$
\end_inset

 is 
\begin_inset Formula $\{S_{m=(1,\dots,M)}\in D|h_{m}<h_{u}\}$
\end_inset

 or more briefly as 
\begin_inset Formula $S_{m}$
\end_inset

 which represents all locations within some distance to the statistical
 node 
\begin_inset Formula $\{h_{u}|\rho(h_{u})_{\text{Matérn}}>0.1\}$
\end_inset

; that is, the distance at which the local spatial autocorrelation drops
 to a negligible value (arbitrarily taken as 
\begin_inset Formula $\rho>0.1$
\end_inset

) and associated parameter values are 
\begin_inset Quotes qld
\end_inset

supported
\begin_inset Quotes qrd
\end_inset

.

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\xout off
\uuline off
\uwave off
\noun off
\color none
 The data found within the subdomain 
\begin_inset Formula $m$
\end_inset

 is 
\begin_inset Formula $\{Y_{s,t}|(s,t)\in D|h_{m}<h_{u}\}$
\end_inset

 and is notationally abbreviated as 
\begin_inset Formula $Y_{s,t|m}$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename concept1.svg
	lyxscale 20
	scale 20

\end_inset


\end_layout

\begin_layout Standard
Figure 5.1 Spatial distribution of data (blue dots) overlaid by a statistical
 grid in
\series bold
 stmv
\series default
.
 The 
\begin_inset Formula $m$
\end_inset

 nodes represent the centers of each local subdomain
\begin_inset Formula $S_{m}$
\end_inset

 which extends to a distance (right-facing arrows; solid squares) that varies
 depending upon the underlying spatial variability of the data and is defined
 in
\series bold
 stmv
\series default
 as the distance at which the spatial autocorrelation drops to some small
 value (
\begin_inset Formula $\rho>0.1$
\end_inset

).
 Data within this distance and parameters obtained from the local analysis
 are, under the assumption of second order stationarity, used to complete
 the local model of the spatial or spatiotemporal processes and then predict/int
erpolate to some fraction of the distance between statistical grid nodes
 (default is 95%; stippled square).
 Every statistical node is visited.
 Any overlapping predictions are locally averaged (weighted by number of
 predictions and prediction variance).
 As grid size decreases the number of models increases.
 This reduces computational load and RAM requirements; however, the utility
 of the model also declines due to small sample sizes entering analyses.
 Judicious choice of statistical grid density as well as maximum and minimum
 number of data points and upper and lower bounds of spatial bounds must
 be balanced.
 This balancing has not been made automatic as the balance depends upon
 data density.
\end_layout

\begin_layout Standard
Operating upon all components of the regression model simultaneously is
 computationally prohibitive.
 Even with very simplistic Generalized Additive Model (GAM) or Generalized
 Additive Mixed effects Model (GAMM) parameterizations of spatial and temporal
 structure, the solutions take many days/weeks on fast machines (5 GHz CPU,
 64GB RAM in 2016), depending of course upon the amount of data and resolution
 and model complexity.
 As a compromise between model complexity and computational speed,
\series bold
 stmv
\series default
 uses a global covariate model
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
 
\begin_inset Formula $F(\cdot)\equiv\boldsymbol{x}_{s,t}^{T}\boldsymbol{\beta}_{s,t}$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
 parameterized using a linear, generalized linear or generalized additive
 model.
 Here, 
\begin_inset Formula $F(\cdot)$
\end_inset

 represents some potential penalized basis splines of low order (3 knots
 or less seem biologically plausible when modality can be expected) of the
 covariate predictors and potentially some function 
\begin_inset Formula $g(\cdot)$
\end_inset

 that represents a link function such that the residual error in the link-space
 can be assumed to be Normal with mean zero and standard deviation
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
 
\begin_inset Formula $\sigma_{\varphi}$
\end_inset

, the latter
\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
 accounting for the residual error process 
\begin_inset Formula $\varphi_{s,t}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{matrix}g(Y_{s,t}) & = & F(\cdot)+\varphi_{s,t},\\
\varphi_{s,t} & \sim & \text{Normal}(0,\sigma_{\varphi}^{2}).
\end{matrix}
\]

\end_inset


\end_layout

\begin_layout Standard
The spatiotemporal structure is decomposed from this residual error process
 and so the approach is in fact quite similar to 
\begin_inset Quotes qld
\end_inset

regression kriging
\begin_inset Quotes qrd
\end_inset

 and (universal) 
\begin_inset Quotes qld
\end_inset

kriging with external drift
\begin_inset Quotes qrd
\end_inset

 (Hengl et al.
 2004).
\end_layout

\begin_layout Standard
The local spatial autocorrelation scale is derived from a rapid (coarse
 grained) fit of the local residuals 
\begin_inset Formula $\varphi_{s,t|m}$
\end_inset

 to a Matérn autocorrelation function.
 To be symmetrical in time, one would also need to determine temporal nodes
 and define appropriate temporal autocorrelation scales.
 In practice, temporal data are often sparse and limiting in survey data
 and so data from all time periods are used to determine a crude scaling,
 essentially amounting to a temporally averaged spatial autocorrelation.
 Once the approximate bounds of the subdomain (support) are estimated, the
 
\begin_inset Formula $\varphi_{s,t|m}$
\end_inset

 are modeled as some function 
\begin_inset Formula $f_{m}(\cdot)\equiv\boldsymbol{\varphi}_{s,t|m}^{T}\boldsymbol{\beta}_{s,t|m}$
\end_inset

 of a Fourier series with two harmonics, one interannual and one subannual
 (seasonal):
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
 
\begin_inset Formula $f_{m}(\text{interannual, seasonal})$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
.
 In other words, a full temporal autocorrelation (covariance) model is not
 used but rather one that uses only a subset of the components at fixed
 wavelengths:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{matrix}\varphi_{s,t|m} & = & f_{m}(\cdot)+\zeta_{s,t|m},\\
\zeta_{s,t|m} & \sim & \text{Normal}(0,\sigma_{\zeta|m}^{2}).
\end{matrix}
\]

\end_inset


\end_layout

\begin_layout Standard
Data are (optionally) weighted by the inverse squared distance 
\begin_inset Formula $h_{m}^{-2}$
\end_inset

 from the coordinates of each statistical node
\begin_inset Formula $m$
\end_inset

 to make data closer to the area of interest and prediction more influential.
 The temporal autocorrelation is, therefore, carried by the individual temporal
 processes at each spatial datum and the temporally structured error 
\begin_inset Formula $\sigma_{t|m}$
\end_inset

 is the variance component of the model 
\begin_inset Formula $f_{m}(\cdot)$
\end_inset

, that is, 
\begin_inset Formula $\sigma_{t|m}=\text{Var}[\varphi_{s,t|m}]-\sigma_{\zeta|m}^{2}$
\end_inset

.
\end_layout

\begin_layout Standard
The spatial autocorrelation function is parameterized as being derived from
 the subdomain mean Gaussian process with a Matérn covariance function with
 parameters 
\begin_inset Formula $\theta_{m}=\{\phi_{m},\nu_{m}\}$
\end_inset

 and a time-varying
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
 spatially structured standard error 
\begin_inset Formula $\sigma_{s|m}$
\end_inset

.
 As the data used to estimate the spatial autocorrelation structure are
 often sparse, the data are augmented by temporal predictions of the residual
 error process at each spatial datum (and notationally designated by an
 asterisk).
 These temporally
\begin_inset Quotes qld
\end_inset

augmented
\begin_inset Quotes qrd
\end_inset

 residual processes are modeled spatially at each time slice 
\begin_inset Formula $\varphi_{s,t|m}^{*}$
\end_inset

 as the sum of a time-varying spatial
\series bold
 Gaussian process
\series default
 
\begin_inset Formula $\omega_{s,t|m}$
\end_inset

 parameterized as a Matérn spatial covariance function 
\begin_inset Formula $\sigma_{s,t|m}^{2}\frac{1}{2^{\nu_{t|m}-1}\Gamma(\nu_{t|m})}(\sqrt{2\nu_{t|m}}h/\phi_{t|m})^{\nu_{t|m}}\ K_{\nu_{t|m}}(\sqrt{2\nu_{t|m}}h/\phi_{t|m})$
\end_inset

 with a local spatial error
\series medium
 
\begin_inset Formula $\sigma_{s,t|m}$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
; and a spatially and temporally unstructured error process assumed to be
 derived from a Normal error process with mean zero and error 
\begin_inset Formula $\sigma_{\varepsilon|m}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{matrix}\varphi_{s,t|m}^{*} & = & \omega_{s,t|m}+\varepsilon_{s,t|m},\\
\omega_{s,t|m} & \sim & \text{GP}(0,C(\mathbf{s},\mathbf{s}';\mathbf{\theta}_{t|m}=\{\nu_{t|m},\phi_{t|m},\sigma_{t|m}\})),\\
\varepsilon_{s,t|m} & \sim & \text{Normal}(0,\sigma_{\varepsilon|m}^{2}).
\end{matrix}
\]

\end_inset


\end_layout

\begin_layout Standard
The current approach represents a practical balance between computational
 time and model complexity/realism.

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
 For additional speed, an FFT-based Matérn convolution implementation is
 used.
\end_layout

\begin_layout Standard
As
\series bold
 stmv
\series default
 focuses upon prediction using a mosaic of solutions in space, overall likelihoo
d or AIC evaluation is a challenge.
 At present, predictive success is the only means to evaluate utility and
 eventually some form of Expectation-Maximization approaches might be fruitful,
 once computational speeds improve.
 A fully Bayesian approach is being considered that removes the need to
 work with
\begin_inset Quotes qld
\end_inset

external drift
\begin_inset Quotes qrd
\end_inset

 and facilitates global model evaluation.
 However, this approach is also awaiting increased computational power.
 These and other more flexible and complex models can be defined in this
 modular framework and they will be expanded upon in future versions of
 this document.
\end_layout

\begin_layout Standard
To facilitate usage and mapping of 
\series bold
stmv
\series default
 to other domains, the data handling methods and model parameterizations
 are encoded in a separate R-library,
\series bold
 aegis
\series default
 which can be found at http://github.com/jae0/aegis.
\end_layout

\begin_layout Section
Using stmv
\end_layout

\begin_layout Standard
The stmv library depends upon a number of important R-packages.
 The full list is: alphahull, bigmemory, devtools, ff, fields, gstat, geoR,
 lattice, lubridate, mgcv, mvtnorm, parallel, sp, rgdal, RandomFields, RandomFie
ldsUtils, truncnorm.
 It also uses the aegis, aegis.env packages which are found only on github.
 The latter two optionally uses raster, maps, mapdata, ROracle.
 Most dependencies should be pulled in automatically, but there may need
 to be some manual intervention.
 By default, bigmemory is used as a storage engine to facilitate parallel
 operations.
 In Linux, the use of parallel operations through MPI or socket communication
 is well established.
 With proprietary operating systems, parallel functionality is not certain
 and so one may be forced to use local cores only.
 In using
\series bold
 stmv
\series default
 on clusters, one must be careful of the amount of communications overhead
 especially when large data volumes are involved.
 Your mileage will vary.
 For most usage, local-core operations should be sufficient.
\end_layout

\begin_layout Standard
The following is the primary call to the library:
\end_layout

\begin_layout Quotation

\size scriptsize
stmv( p=p )
\end_layout

\begin_layout Standard
All functionally is controlled through the options specified in the parameter
 list 
\begin_inset Quotes qld
\end_inset

p
\begin_inset Quotes qrd
\end_inset

.
 Most of the defaults options work well and should only be altered if absolutely
 necessary.
 The more user-modifiable options are listed in the examples below with
 explanations.
\end_layout

\begin_layout Subsection
Example 1: pure spatial models – bathymetry and substrate grain size
\end_layout

\begin_layout Standard
As some oceanographic features change on geological time scales, we can
 treat them as a pure spatial problem, though of course, in reality they
 are not truly static.
 Bathymetry (depth; m; =-elevation) is one such feature that is highly informati
ve in that it determines ambient light levels, surface complexity/rugosity,
 hydrodynamic stability and overall environmental stability.
 Here, we model it as a Lognormal process using
\series bold
 stmv
\series default
:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{matrix}\text{log}(Y_{s}) & = & F(\text{constant offset})+\varphi_{s},\\
\varphi_{s} & \sim & \text{Normal}(0,\sigma_{\varphi}^{2}),\\
\varphi_{s|m} & = & \omega_{s|m}+\varepsilon_{s|m},\\
\omega_{s|m} & \sim & \text{GP}(0,C(\mathbf{s},\mathbf{s}';\mathbf{\theta}_{m}=\{\nu_{m},\phi_{m},\sigma_{m}\})),\\
\varepsilon_{s|m} & \sim & \text{Normal}(0,\sigma_{\varepsilon|m}^{2}).
\end{matrix}
\]

\end_inset


\end_layout

\begin_layout Standard
As it is a pure space model, there is no need to temporally 
\begin_inset Quotes qld
\end_inset

augment
\begin_inset Quotes qrd
\end_inset

 the data leaving a direct decomposition of the global residual error process
 
\begin_inset Formula $\varphi_{s|m}$
\end_inset

 into a local spatial process 
\begin_inset Formula $\omega_{s|m}$
\end_inset

 and a local unstructured error
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
 
\begin_inset Formula $\varepsilon_{s|m}$
\end_inset

.
 An FFT-based Matérn convolution implementation is used to express the spatial
 process for computational speed improvements.
\end_layout

\begin_layout Standard
We demonstrate how to formulate the above model with example data provided
 in stmv:
\end_layout

\begin_layout Quotation

\size scriptsize
# parameter list defining the spatial bounds and dimensions 
\end_layout

\begin_layout Quotation

\size scriptsize
p0 = stmv_test_data( "aegis.test.paramaters") 
\end_layout

\begin_layout Quotation
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Quotation

\size scriptsize
# alternatively, one can explicitly construct the above parameter list which
 amounts to: 
\end_layout

\begin_layout Quotation

\size scriptsize
p0 = aegis::spatial_parameters( 
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
spatial.domain="bathymetry_example", # aribtrary name 
\end_layout

\begin_layout Quotation

\size scriptsize
internal.crs="+proj=utm +ellps=WGS84 +zone=20 +units=km", # planar projection
 of input data 
\end_layout

\begin_layout Quotation

\size scriptsize
dres=1/60/4, # discretization scale 
\end_layout

\begin_layout Quotation

\size scriptsize
pres=0.5, # spatial resolution km
\end_layout

\begin_layout Quotation

\size scriptsize
lon0=-64, # min longitude
\end_layout

\begin_layout Quotation

\size scriptsize
lon1=-62, # max longitude
\end_layout

\begin_layout Quotation

\size scriptsize
lat0=44, # min latitude
\end_layout

\begin_layout Quotation

\size scriptsize
lat1=45, # max latitude
\end_layout

\begin_layout Quotation

\size scriptsize
psignif=2 # planar coordinates number of digits of significance
\end_layout

\end_deeper
\begin_layout Quotation

\size scriptsize
) 
\end_layout

\begin_layout Quotation

\size scriptsize
str(p0)
\end_layout

\begin_layout Quotation
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Quotation

\size scriptsize
# load the saved spatial data
\end_layout

\begin_layout Quotation

\size scriptsize
spatial_data = stmv::stmv_test_data( datasource="aegis.space", p=p0) # extract
 of some depth data
\end_layout

\begin_layout Quotation

\size scriptsize
spatial_data = lonlat2planar( spatial_data, p0$internal.crs ) # convert to
 planar coordinate system (UTM20) 
\end_layout

\begin_layout Quotation

\size scriptsize
spatial_data = spatial_data[, c("plon", "plat", "z")]
\end_layout

\begin_layout Quotation
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Quotation

\size scriptsize
# quick look of data 
\end_layout

\begin_layout Quotation

\size scriptsize
str (spatial_data)
\end_layout

\begin_layout Quotation

\size scriptsize
require (fields) 
\end_layout

\begin_layout Quotation

\size scriptsize
dev.new(); 
\end_layout

\begin_layout Quotation

\size scriptsize
surface( as.image( Z=spatial_data$z, x=spatial_data[, c("plon", "plat")],
 nx=p0$nplons, ny=p0$nplats, na.rm=TRUE) )
\end_layout

\begin_layout Standard
This data is added to a structured list for input to 
\series bold
stmv 
\series default
as follows:
\end_layout

\begin_layout Quotation

\size scriptsize
# construct parameter list controlling stmv
\end_layout

\begin_layout Quotation

\size scriptsize
scale_ncpus = 4 # depends upon how many core you have and the size of the
 problem
\end_layout

\begin_layout Quotation

\size scriptsize
interpolate_ncpus = 4 # depends upon how many core you have
\end_layout

\begin_layout Quotation

\size scriptsize
p = aegis.bathymetry::bathymetry_parameters( 
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
p = p0, # start with spatial settings of input data and add to it 
\end_layout

\begin_layout Quotation

\size scriptsize
project.mode="stmv", 
\end_layout

\begin_layout Quotation

\size scriptsize
data_root = file.path(work_root, "bathymetry_example"), 
\end_layout

\begin_layout Quotation

\size scriptsize
DATA = list( 
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
input = c, 
\end_layout

\begin_layout Quotation

\size scriptsize
output = list( LOCS = spatial_grid(p0) ) 
\end_layout

\end_deeper
\begin_layout Quotation

\size scriptsize
), 
\end_layout

\begin_layout Quotation

\size scriptsize
spatial.domain = p0$spatial.domain, # name to use, defined above
\end_layout

\begin_layout Quotation

\size scriptsize
pres_discretization_bathymetry = p0$pres, # defined above
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_dimensionality="space", # pure space model
\end_layout

\begin_layout Quotation

\size scriptsize
variables = list(Y="z"), # required as fft has no formulae interface (yet)
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_global_modelengine = "none", # too much data to use glm as an entry
 into link space ...
 use a direct transformation stmv_local_modelengine="fft", 
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_fft_filter = "matern_tapered", # matern with taper, tapering the autocorrel
ation function reduces oversmoothing 
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_fft_taper_method = "modelled", # vs "empirical" 
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_variogram_method = "fft", 
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_autocorrelation_fft_taper = 0.5, # autocorrelation value below which
 to taper 
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_autocorrelation_localrange = 0.1, # autocorrelation value of the 
\begin_inset Quotes qld
\end_inset

practical range
\begin_inset Quotes qrd
\end_inset

 that is to 
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_autocorrelation_interpolation = c(0.3, 0.2, 0.1, 0.05, 0.01), # interpolate
 at practical ranges defined at these autocorrelation values
\end_layout

\begin_layout Quotation

\size scriptsize
depth.filter = FALSE, # need data above sea level to get coastline 
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_Y_transform =list( 
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
transf = function(x) {log10(x + 2500)} , 
\end_layout

\begin_layout Quotation

\size scriptsize
invers = function(x) {10^(x) - 2500} ), # data range is from -1667 to 5467
 m: make all positive valued 
\end_layout

\end_deeper
\begin_layout Quotation

\size scriptsize
stmv_rsquared_threshold = 0, # lower threshold ..
 i.e., ignore ...
 there is no timeseries model, nor a fixed effect spatial "model" stmv_distance_
statsgrid = 5, # resolution (km) of data aggregation (i.e.
 generation of the ** statistics ** ) 
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_distance_scale = c( 2.5, 5, 10, 20, 40 ), # km ...
 approx guesses of 95% AC range 
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_distance_prediction_fraction = 0.95, # i.e.
 4/5 * 5 = 4 km ..
 relative to stats grid 
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_nmin = 200, # min number of data points req before attempting to model
 in a localized space 
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_nmax = 400, # no real upper bound..
 just speed /RAM 
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_force_complete_method = "linear", 
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_runmode = list( 
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
scale = rep("localhost", scale_ncpus), # ncpus for each runmode 
\end_layout

\begin_layout Quotation

\size scriptsize
interpolate = list( 
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
cor_0.5 = rep("localhost", interpolate_ncpus), 
\end_layout

\begin_layout Quotation

\size scriptsize
cor_0.25 = rep("localhost", interpolate_ncpus), 
\end_layout

\begin_layout Quotation

\size scriptsize
cor_0.1 = rep("localhost", max(1, interpolate_ncpus-1)), 
\end_layout

\begin_layout Quotation

\size scriptsize
cor_0.01 = rep("localhost", max(1, interpolate_ncpus-2)) ), # ncpus for each
 runmode 
\end_layout

\end_deeper
\begin_layout Quotation

\size scriptsize
interpolate_force_complete = rep("localhost", max(1, interpolate_ncpus-2)),
 
\end_layout

\begin_layout Quotation

\size scriptsize
globalmodel = FALSE, 
\end_layout

\begin_layout Quotation

\size scriptsize
restart_load = FALSE, 
\end_layout

\begin_layout Quotation

\size scriptsize
save_completed_data = TRUE # just a dummy variable with the correct name
 ) )
\end_layout

\end_deeper
\end_deeper
\begin_layout Quotation

\size scriptsize
p$spatial.domain.subareas =NULL
\end_layout

\begin_layout Quotation

\size scriptsize
spatial_data =NULL; gc() # clear RAM in preparation for the run
\end_layout

\begin_layout Quotation
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Quotation

\size scriptsize
# call stmv to run 
\end_layout

\begin_layout Quotation

\size scriptsize
stmv( p=p ) # This will take from a few minutes, depending upon system #
 stmv_db( p=p, DS="cleanup.all" )
\end_layout

\begin_layout Quotation
\begin_inset VSpace defskip
\end_inset


\size scriptsize
# obtain stmv results
\end_layout

\begin_layout Quotation

\size scriptsize
predictions = stmv_db( p=p, DS="stmv.prediction", ret="mean" ) 
\end_layout

\begin_layout Quotation

\size scriptsize
statistics = stmv_db( p=p, DS="stmv.stats" ) 
\end_layout

\begin_layout Quotation

\size scriptsize
locations = spatial_grid( p ) 
\end_layout

\begin_layout Quotation
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Quotation

\size scriptsize
(p$statsvars) # p$statsvars = c( "sdTotal", "rsquared", "ndata", "sdSpatial",
 "sdObs", "phi", "nu", "localrange" ) 
\end_layout

\begin_layout Quotation

\size scriptsize
dev.new(); levelplot( predictions[] ~ locations[,1] + locations[,2], aspect="iso"
 ) 
\end_layout

\begin_layout Quotation

\size scriptsize
dev.new(); levelplot( statistics[,match("nu", p$statsvars)] ~ locations[,1]
 + locations[,2], aspect="iso" ) # nu 
\end_layout

\begin_layout Quotation

\size scriptsize
dev.new(); levelplot( statistics[,match("sdTotal", p$statsvars)] ~ locations[,1]
 + locations[,2], aspect="iso" ) #sd total 
\end_layout

\begin_layout Quotation

\size scriptsize
dev.new(); levelplot( statistics[,match("localrange", p$statsvars)] ~ locations[,
1] + locations[,2], aspect="iso" ) #localrange
\end_layout

\begin_layout Standard
Once complete, wrapping functions exist within
\series bold
 aegis
\series default
 to assimilate the results and continue with analysis and figure generation.
 However, this requires the complete 
\series bold
aegis
\series default
 data structures to be available.
 Looking at the internals of the following function will assist in developing
 approaches to data assimilation for your own projects:
\end_layout

\begin_layout Quotation

\size scriptsize
aegis::bathymetry.db( p=p, DS="complete.redo" ) # finalise
\end_layout

\begin_layout Standard
Similar to the case of bathymetry, substrate grain size (mm) can be considered
 a pure space model as it also varies at geological time scales.
 Of course, catastrophically rapid changes can and do occur but these can
 be still be considered statically if we are not focussed upon the geological
 processes.
 Grain size is ultimately a proxy measure of the type of substrate (mud,
 sand, gravel, rock, etc.) and so can be informative for benthic, demersal
 and infaunal organisms.
 Unfortunately, the only available data currently available is an (over-)smoothe
d surface provided by Kostylev and Hannah (2007).
 Some data have been added from the snow crab surveys.
 It is also modeled as a Lognormal process, with an FFT based Matérn covariance:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{matrix}\text{log}(Y_{s}) & = & F(\text{depth, slope, curvature})+\varphi_{s},\\
\varphi_{s} & \sim & \text{Normal}(0,\sigma_{\varphi}^{2}),\\
\varphi_{s|m} & = & \omega_{s|m}+\varepsilon_{s|m},\\
\omega_{s|m} & \sim & \text{GP}(0,C(\mathbf{s},\mathbf{s}';\mathbf{\theta}_{m}=\{\nu_{m},\phi_{m},\sigma_{m}\})),\\
\varepsilon_{s|m} & \sim & \text{Normal}(0,\sigma_{\varepsilon|m}^{2}).
\end{matrix}
\]

\end_inset


\end_layout

\begin_layout Standard
The data associated with substrate grain size has not yet been released
 and so no example data is provided with 
\series bold
stmv
\series default
.
 The following is the parameterization used internally by 
\series bold
aegis.
 
\series default
It demonstrates the use of a global (fixed effect, external drift) model,
 in this case a simple Generalized Additive model.
\end_layout

\begin_layout Quotation

\size scriptsize
ram_required_main_process = 3 # GB
\end_layout

\begin_layout Quotation

\size scriptsize
ram_required_per_process = 2 # GB in 2017, approximate upper bound, usually
 2-4 GB/process
\end_layout

\begin_layout Quotation

\size scriptsize
ncpu = min( parallel::detectCores(), floor( (ram_local()-ram_required_main_proce
ss) / ram_required_per_process ) )
\end_layout

\begin_layout Quotation

\size scriptsize
p = aegis::aegis_parameters(
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
DS = "substrate",
\end_layout

\begin_layout Quotation

\size scriptsize
data_root = project.datadirectory( "aegis", "substrate" ),
\end_layout

\begin_layout Quotation

\size scriptsize
spatial.domain = c( "canada.east.highres"),
\end_layout

\begin_layout Quotation

\size scriptsize
spatial.domain.subareas = c( "canada.east.highres", "canada.east", "SSE", "snowcrab",
 "SSE.mpa" ),
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_dimensionality="space",
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_global_modelengine = "gam", # generalized additive model
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_global_modelformula = formula( paste(
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
'substrate.grainsize ~ s( b.sdTotal, k=3, bs="ts") + s(log(z), k=3, bs="ts")
 ',
\end_layout

\begin_layout Quotation

\size scriptsize
'+s(log(dZ), k=3, bs="ts") +s(log(ddZ), k=3, bs="ts") + s(log(b.range), k=3,
 bs="ts")') ), # a GAM model
\end_layout

\end_deeper
\begin_layout Quotation

\size scriptsize
stmv_global_family = gaussian(link="log"),
\end_layout

\begin_layout Quotation

\size scriptsize
# a log-normal works ok but a model of log-transformed data works better
 ..
 ie, working upon medians which is really OK
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_local_modelengine="fft", # currently the preferred approach
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_lowpass_phi = 1*2, # p$res *2 = 1 *2:: FFT based method when operating
 globally
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_lowpass_nu = 0.5, # this is exponential covar
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_variogram_method = "fft",
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_eps = 0.001, # distance units for eps noise to permit mesh gen for boundarie
s
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_rsquared_threshold = 0.1, # lower threshold
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_distance_statsgrid = 5, # resolution (km) of data aggregation (i.e.
 generation of the ** statistics ** )
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_distance_scale = c(30, 40, 50), # km ...
 approx guess of 95% AC range
\end_layout

\begin_layout Quotation

\size scriptsize
depth.filter = 0.1, # the depth covariate is input in m, so, choose stats
 locations with elevation > 0 m as being on land
\end_layout

\begin_layout Quotation

\size scriptsize
n.min = 400, # n.min/n.max changes with resolution
\end_layout

\begin_layout Quotation

\size scriptsize
n.max = 4000, # numerical time/memory constraint -- anything larger takes
 too much time ..
 anything less ..
 errors
\end_layout

\begin_layout Quotation

\size scriptsize
clusters=rep("localhost", ncpu ))
\end_layout

\end_deeper
\begin_layout Quotation

\size scriptsize
)
\end_layout

\begin_layout Quotation

\size scriptsize
stmv( p=p, runmode=c("globalmodel", "interpolate" ) ) # no global_model
 and force a clean restart
\end_layout

\begin_layout Quotation

\size scriptsize
substrate.db( p=p, DS="complete.redo" ) # gather results
\end_layout

\begin_layout Subsection
Example 2: inseparable spatiotemporal model of temperature
\end_layout

\begin_layout Standard
Temperature is a fundamental modulator of metabolism, growth, reproduction,
 predator and prey distribution and abundance, disease incidence, species
 composition, etc.
 Bottom temperatures, in particular, are the focus due to their relevance
 to benthic and demersal organisms and modeled as an hierarchical, spatiotempora
l,
\begin_inset Quotes eld
\end_inset

inseparable
\begin_inset Quotes erd
\end_inset

 spatiotemporal process.
 As they have high frequency variations, some additional complexity is required
 in modeling their spatiotemporal patterns.
 Here, the temporal effects are nested in spatial subdomains 
\begin_inset Formula $S_{m}$
\end_inset

.
 
\end_layout

\begin_layout Standard
The global covariate model is simply an intercept model with an identity
 link such that 
\begin_inset Formula $\varphi_{s,t}$
\end_inset

 are centered upon zero.
 Salinity or water density data can conceivably enter to delineate water
 masses and origins, however, this data does not exist at sufficient density
 and coverage to be informative enough to merit the additional computational
 load (at present).
 Instead, the residuals errors are modeled locally in each subdomain as
 a weighted timeseries with two Fourier harmonics in time (an interannual
 and a subannual/seasonal component).
 The weights are determined from the inverse squared distance from each
 statistical node 
\begin_inset Formula $h_{m}$
\end_inset

.
 Additional penalized thin-plate spline smooth terms for local depth and
 location are used to resolve local spatial trends and aliasing to third
 order or less (via shrinkage).
 Temporal predictions at each spatial datum are then used to 
\begin_inset Quotes eld
\end_inset

augment
\begin_inset Quotes erd
\end_inset

 the modeling of the spatial processes 
\begin_inset Formula $\varphi_{s,t|m}^{*}$
\end_inset

 which are treated independently for each time slice as a
\series bold
 Gaussian process
\series default
.
 The temporal autocorrelation is, therefore, carried only indirectly by
 the individual temporal processes centered at each spatial datum.
 For faster computations, a Fast Fourier Transform (FFT) based convolution
 method is used to approximate the spatial Gaussian process.
 The model specification is, therefore:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{matrix}Y_{s,t} & = & F(\text{identity})+\varphi_{s,t},\\
\varphi_{s,t} & \sim & \text{Normal}(0,\sigma_{\varphi}^{2}),\\
\varphi_{s,t|m} & = & f_{m}(\text{interannual,seasonal,northing,easting,depth})+\zeta_{s,t|m}\\
\zeta_{s,t|m} & \sim & \text{Normal}(0,\sigma_{\zeta|m}^{2}),\\
\varphi_{s,t|m}^{*} & = & \omega_{s,t|m}+\varepsilon_{s,t|m},\\
\omega_{s,t|m} & \sim & \text{GP}(0,C(\mathbf{s},\mathbf{s}';\mathbf{\theta}_{t|m}=\{\nu_{t|m},\phi_{t|m},\sigma_{t|m}\})),\\
\varepsilon_{s,t|m} & \sim & \text{Normal}(0,\sigma_{\varepsilon|m}^{2}).
\end{matrix}
\]

\end_inset


\end_layout

\begin_layout Standard
The temperature data originate from a number of different sources, including
 the snow crab survey, groundfish survey, AZMP survey, FSRS survey, scallop
 survey and many other opportunistic samples maintained and kindly provided
 by Roger Petitpas (OSD, DFO).
 It can be parameterized as:
\end_layout

\begin_layout Quotation

\size scriptsize
year.assessment = 2017
\end_layout

\begin_layout Quotation

\size scriptsize
ram_required_main_process = 22 # GB
\end_layout

\begin_layout Quotation

\size scriptsize
ram_required_per_process = 4 # GB in 2017, for GAM
\end_layout

\begin_layout Quotation

\size scriptsize
ncpu = min( parallel::detectCores(), floor( (ram_local()-ram_required_main_proce
ss) / ram_required_per_process ) )
\end_layout

\begin_layout Quotation

\size scriptsize
p = aegis::aegis_parameters(
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
year.assessment=year.assessment,
\end_layout

\begin_layout Quotation

\size scriptsize
DS = "temperature",
\end_layout

\begin_layout Quotation

\size scriptsize
data_root = project.datadirectory( "aegis", "temperature" ),
\end_layout

\begin_layout Quotation

\size scriptsize
spatial.domain = "canada.east", # default
\end_layout

\begin_layout Quotation

\size scriptsize
DATA = 'temperature.db( p=p, DS="stmv.inputs" )',
\end_layout

\begin_layout Quotation

\size scriptsize
additional.data=c("groundfish", "snowcrab", "USSurvey_NEFSC", "lobster"),
\end_layout

\begin_layout Quotation

\size scriptsize
pres_discretization_temperature = 1 / 100, # 1==p$pres; controls resolution
 of data prior to modeling (km ..
 ie 100 linear units smaller than the final discretization pres)
\end_layout

\begin_layout Quotation

\size scriptsize
yrs = 1950:year.assessment,
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_dimensionality="space-time-cyclic",
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_global_modelengine = "none",
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_global_modelformula = "none", # only marginally useful ..
 consider removing it and use "none",
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_global_family ="none",
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_local_modelengine = "twostep" ,
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_twostep_time = "gam",
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_local_modelformula_time = formula( paste(
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
't', '~ s(yr, k=12, bs="ts") + s(cos.w, k=3, bs="ts") + s(sin.w, k=3, bs="ts")
 ',
\end_layout

\begin_layout Quotation

\size scriptsize
'+ s( cos.w, sin.w, yr, k=50, bs="ts")',
\end_layout

\begin_layout Quotation

\size scriptsize
'+ s(log(z), k=3, bs="ts") '
\end_layout

\end_deeper
\begin_layout Quotation

\size scriptsize
) ) ,
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_twostep_space = "fft", # everything else is too slow ...
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_fft_filter="matern", # matern, krige (very slow), lowpass, lowpass_matern
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_local_model_distanceweighted = TRUE,
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_gam_optimizer=c("outer", "bfgs"),
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_variogram_method = "gstat",
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_eps = 0.1, # distance units for eps noise to permit mesh gen for boundaries
 (INLA-based methods)
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_rsquared_threshold = 0, # lower threshold ..
 not used if twostep method
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_distance_statsgrid = 10, # resolution (km) of data aggregation (i.e.
 generation of the ** statistics ** )
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_distance_scale = c(30, 40, 50), # km ...
 approx guess of 95% AC range
\end_layout

\begin_layout Quotation

\size scriptsize
n.min = 20*(year.assessment-1950), # ~ 1000 min number of data points req
 before attempting to model timeseries in a localized space
\end_layout

\begin_layout Quotation

\size scriptsize
n.max = 5000, # no real upper bound..
 just speed / RAM limits
\end_layout

\begin_layout Quotation

\size scriptsize
clusters = rep("localhost", ncpu)
\end_layout

\end_deeper
\begin_layout Quotation

\size scriptsize
)
\end_layout

\begin_layout Quotation

\size scriptsize
stmv( p=p, runmode="interpolate")
\end_layout

\begin_layout Quotation

\size scriptsize
temperature.db( p=p, DS="predictions.redo" ) # 10 min
\end_layout

\begin_layout Quotation

\size scriptsize
temperature.db( p=p, DS="stmv.stats.redo" ) # warp to sub grids
\end_layout

\begin_layout Subsection
Example 3: inseparable spatiotemporal model of snow crab habitat and abundance
\end_layout

\begin_layout Standard
The snow crab estimation process uses the above and other covariates interpolate
d to the same continuous spatial support of the snow crab assessment.
 This is required to refine predictions of snow crab abundance and habitat
 while avoiding issues of bias due to aliasing (also known as 
\begin_inset Quotes qld
\end_inset

upscaling
\begin_inset Quotes qrd
\end_inset

 and 
\begin_inset Quotes qld
\end_inset

downscaling
\begin_inset Quotes qrd
\end_inset

 issues).
 Some of these covariates change on geological time scales relative to the
 timescale of the biological and ecological processes of interest and so
 can be considered functionally a
\begin_inset Quotes eld
\end_inset

pure
\begin_inset Quotes erd
\end_inset

 spatial model (though of course they are not truly static).
 And others that are more biological in nature vary at similar or even shorter
 time scales and so require a temporal component.
 Here we detail some of these core data sources and their model assumptions
 in the context of the temporal autocorrelation scale of snow crab abundance
 in the Maritimes Region of Canada.
\end_layout

\begin_layout Standard
Additional covariates that express the ecosystem state at a given time and
 location (
\begin_inset Quotes qld
\end_inset

indicators
\begin_inset Quotes qrd
\end_inset

) are informative in delineating spatiotemporal processes that are structured
 from those that are random.
 Their model formulation is similar in that they follow a similar model
 structure with temporal effects nested in spatial subdomains and the use
 of link functions in a Generalized Linear Model/Generalized Additive Model
 setting where the covariates used to model these indicators rely upon spatial
 predictions of depth and substrate grain size and the spatial derivatives
 of the former (slope and curvature).
 The spatiotemporal error process is modeled locally in each subdomain as
 a space-time 
\begin_inset Quotes qld
\end_inset

inseparable
\begin_inset Quotes qrd
\end_inset

 model, using time-varying covariates related to bottom temperature variations
 and associated statistics:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{matrix}g(Y_{s,t}) & = & F(\text{depth, slope, curvature, substrate grainsize})+\varphi_{s,t}\\
\varphi_{s,t} & \sim & \text{Normal}(0,\sigma_{\varphi}^{2}),\\
\varphi_{s,t|m} & = & f_{m}(\text{interannual,seasonal,northing,easting,depth})+\zeta_{s,t|m}\\
\zeta_{s,t|m} & \sim & \text{Normal}(0,\sigma_{\zeta|m}^{2}),\\
\varphi_{s,t|m}^{*} & = & \omega_{s,t|m}+\varepsilon_{s,t|m},\\
\omega_{s,t|m} & \sim & \text{GP}(0,C(\mathbf{s},\mathbf{s}';\mathbf{\theta}_{t|m}=\{\nu_{t|m},\phi_{t|m},\sigma_{t|m}\})),\\
\varepsilon_{s,t|m} & \sim & \text{Normal}(0,\sigma_{\varepsilon|m}^{2}).
\end{matrix}
\]

\end_inset


\end_layout

\begin_layout Standard
For the estimation of habitat preferences and the creation of species distributi
on maps that rely upon presence-absence data.
 The data 
\begin_inset Formula $Y$
\end_inset

 are assumed to come from a Bernoulli binomial process with a logit link
 function 
\begin_inset Formula $g(\cdot)$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{matrix}\text{logit}(Y_{s,t}) & = & F(\text{depth, slope, curvature, substrate grainsize})+\varphi_{s,t}\\
\varphi_{s,t} & \sim & \text{Normal}(0,\sigma_{\varphi}^{2}),\\
\varphi_{s,t|m} & = & f_{m}(\text{ecosystem indicators})+\zeta_{s,t|m}\\
\zeta_{s,t|m} & \sim & \text{Normal}(0,\sigma_{\zeta|m}^{2}),\\
\varphi_{s,t|m}^{*} & = & \omega_{s,t|m}+\varepsilon_{s,t|m},\\
\omega_{s,t|m} & \sim & \text{GP}(0,C(\mathbf{s},\mathbf{s}';\mathbf{\theta}_{t|m}=\{\nu_{t|m},\phi_{t|m},\sigma_{t|m}\})),\\
\varepsilon_{s,t|m} & \sim & \text{Normal}(0,\sigma_{\varepsilon|m}^{2}).
\end{matrix}
\]

\end_inset


\end_layout

\begin_layout Standard
The above model is parameterized as:
\end_layout

\begin_layout Quotation

\size scriptsize
year.assessment = 2017
\end_layout

\begin_layout Quotation

\size scriptsize
p = bio.snowcrab::load.environment( year.assessment=year.assessment )
\end_layout

\begin_layout Quotation

\size scriptsize
p = snowcrab_stmv( p=p, DS="parameters",
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
variables=list(Y="snowcrab.large.males_presence_absence"),
\end_layout

\begin_layout Quotation

\size scriptsize
selection=list(
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
type = "presence_absence",
\end_layout

\begin_layout Quotation

\size scriptsize
biologicals = list(
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
sex=0, # male
\end_layout

\begin_layout Quotation

\size scriptsize
mat=1, # do not use maturity status in groundfish data as it is suspect
 ..
\end_layout

\begin_layout Quotation

\size scriptsize
spec_bio=bio.taxonomy::taxonomy.recode( from="spec", to="parsimonious", tolookup=2
526 ),
\end_layout

\begin_layout Quotation

\size scriptsize
len= c( 95, 200 )/10, # mm -> cm ; aegis_db in cm
\end_layout

\begin_layout Quotation

\size scriptsize
ranged_data="len"
\end_layout

\end_deeper
\begin_layout Quotation

\size scriptsize
),
\end_layout

\begin_layout Quotation

\size scriptsize
survey=list(
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
drop.unreliable.zeros.groundfish.data=TRUE # esp from 1970 to 1999 measurement
 of invertebrates was sporatic ..
 zero-values are dropped as they are unreliable
\end_layout

\end_deeper
\begin_layout Quotation

\size scriptsize
)
\end_layout

\end_deeper
\begin_layout Quotation

\size scriptsize
),
\end_layout

\begin_layout Quotation

\size scriptsize
DATA = 'snowcrab_stmv( p=p, DS="stmv_inputs" )',
\end_layout

\begin_layout Quotation

\size scriptsize
aegis_project_datasources = c("speciescomposition" ),
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_global_family = binomial( link="log" ),
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_global_modelengine ="gam",
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_stmv_global_modelformula = formula( paste(
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
' snowcrab.large.males_presence_absence ~ s(t, k=3, bs="ts") + s(tmean.climatology,
 k=3, bs="ts") + s(tsd.climatology, k=3, bs="ts") ',
\end_layout

\begin_layout Quotation

\size scriptsize
' + s( log(z), k=3, bs="ts") + s( log(dZ), k=3, bs="ts") + s( log(ddZ),
 k=3, bs="ts") ',
\end_layout

\begin_layout Quotation

\size scriptsize
' + s(log(substrate.grainsize), k=3, bs="ts") + s(pca1, k=3, bs="ts") + s(pca2,
 k=3, bs="ts") ' )),
\end_layout

\end_deeper
\begin_layout Quotation

\size scriptsize
stmv_local_modelengine = "twostep",
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_twostep_space = "gam",
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_local_modelformula_space = formula( paste(
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
'snowcrab.large.males_abundance', '~ s(log(z), k=3, bs="ts") + s(plon, k=3,
 bs="ts") + s(plat, k=3, bs="ts") + s( log(z), plon, plat, k=27, bs="ts")
 ') ),
\end_layout

\end_deeper
\begin_layout Quotation

\size scriptsize
stmv_twostep_time = "gam",
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_local_modelformula_time = formula( paste(
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
'snowcrab.large.males_abundance', ' ~ s(yr, k=10, bs="ts") + s(cos.w, k=3,
 bs="ts") + s(sin.w, k=3, bs="ts") ',
\end_layout

\begin_layout Quotation

\size scriptsize
'+ s( cos.w, sin.w, yr, k=45, bs="ts")') ),
\end_layout

\end_deeper
\begin_layout Quotation

\size scriptsize
stmv_gam_optimizer=c("outer", "bfgs"),
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_distance_statsgrid = 2, # resolution (km) of data aggregation (i.e.
 generation of the ** statistics ** ),
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_distance_scale = c(40, 50, 60)
\end_layout

\end_deeper
\begin_layout Quotation

\size scriptsize
)
\end_layout

\begin_layout Quotation

\size scriptsize
stmv( p=p, runmode=c("globalmodel", "interpolate" ) ) # no global_model
 and force a clean restart
\end_layout

\begin_layout Quotation

\size scriptsize
snowcrab_stmv( p=p, DS="predictions.redo" ) # warp predictions to other grids
\end_layout

\begin_layout Quotation

\size scriptsize
snowcrab_stmv( p=p, DS="stmv.stats.redo" ) # warp stats to other grids
\end_layout

\begin_layout Standard
For the estimation of abundance, the positive valued data 
\begin_inset Formula $Y$
\end_inset

 are assumed to come from a lognormal process:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{matrix}\text{log}(Y_{s,t}) & = & F(\text{depth, slope, curvature, substrate grainsize})+\varphi_{s,t}\\
\varphi_{s,t} & \sim & \text{Normal}(0,\sigma_{\varphi}^{2}),\\
\varphi_{s,t|m} & = & f_{m}(\text{ecosystem indicators})+\zeta_{s,t|m}\\
\zeta_{s,t|m} & \sim & \text{Normal}(0,\sigma_{\zeta|m}^{2}),\\
\varphi_{s,t|m}^{*} & = & \omega_{s,t|m}+\varepsilon_{s,t|m},\\
\omega_{s,t|m} & \sim & \text{GP}(0,C(\mathbf{s},\mathbf{s}';\mathbf{\theta}_{t|m}=\{\nu_{t|m},\phi_{t|m},\sigma_{t|m}\})),\\
\varepsilon_{s,t|m} & \sim & \text{Normal}(0,\sigma_{\varepsilon|m}^{2}).
\end{matrix}
\]

\end_inset


\end_layout

\begin_layout Standard
The parametrization of the above model is as follows:
\end_layout

\begin_layout Quotation

\size scriptsize
year.assessment = 2017
\end_layout

\begin_layout Quotation

\size scriptsize
p = bio.snowcrab::load.environment( year.assessment=year.assessment )
\end_layout

\begin_layout Quotation

\size scriptsize
# 11 hrs with these settings,
\end_layout

\begin_layout Quotation

\size scriptsize
p = snowcrab_stmv( p=p, DS="parameters",
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
variables=list(Y="snowcrab.large.males_abundance"),
\end_layout

\begin_layout Quotation

\size scriptsize
sselection=list(
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
type = "abundance",
\end_layout

\begin_layout Quotation

\size scriptsize
biologicals=list(
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
sex=0, # male
\end_layout

\begin_layout Quotation

\size scriptsize
mat=1, # do not use maturity status in groundfish data as it is suspect
 ..
\end_layout

\begin_layout Quotation

\size scriptsize
spec_bio=bio.taxonomy::taxonomy.recode( from="spec", to="parsimonious", tolookup=2
526 ),
\end_layout

\begin_layout Quotation

\size scriptsize
len= c( 95, 200 )/10, # mm -> cm ; aegis_db in cm
\end_layout

\begin_layout Quotation

\size scriptsize
ranged_data="len"
\end_layout

\end_deeper
\begin_layout Quotation

\size scriptsize
),
\end_layout

\begin_layout Quotation

\size scriptsize
survey=list(
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
drop.unreliable.zeros.groundfish.data=TRUE # esp from 1970 to 1999 measurement
 of invertebrates was sporatic ..
 zero-values are dropped as they are unreliable
\end_layout

\end_deeper
\begin_layout Quotation

\size scriptsize
)
\end_layout

\end_deeper
\begin_layout Quotation

\size scriptsize
DATA = 'snowcrab_stmv( p=p, DS="stmv_inputs" )',
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_Y_transform =list(
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
transf = function(x) {x/6675} ,
\end_layout

\begin_layout Quotation

\size scriptsize
invers = function(x) {x*6675}
\end_layout

\end_deeper
\begin_layout Quotation

\size scriptsize
), # transform data to unit interval to stabilize variance and speed up
 convergence
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_global_modelengine ="gam",
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_global_family = gaussian(link="log"),
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_global_modelformula = formula( paste(
\end_layout

\begin_layout Quotation

\size scriptsize
'snowcrab.large.males_abundance', '~ s(t, k=3, bs="ts") + s(tmean.climatology,
 k=3, bs="ts") + s(tsd.climatology, k=3, bs="ts") ',
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
' + s( log(z), k=3, bs="ts") + s( log(dZ), k=3, bs="ts") + s( log(ddZ),
 k=3, bs="ts") ',
\end_layout

\begin_layout Quotation

\size scriptsize
' + s(log(substrate.grainsize), k=3, bs="ts") + s(pca1, k=3, bs="ts") + s(pca2,
 k=3, bs="ts") ' )), # no space
\end_layout

\end_deeper
\begin_layout Quotation

\size scriptsize
stmv_local_modelengine = "twostep",
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_twostep_time = "gam",
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_local_modelformula_time = formula( paste(
\end_layout

\begin_deeper
\begin_layout Quotation

\size scriptsize
'snowcrab.large.males_abundance', '~ s(yr, k=10, bs="ts") + s(cos.w, k=3, bs="ts")
 + s(sin.w, k=3, bs="ts") ',
\end_layout

\begin_layout Quotation

\size scriptsize
' + s(cos.w, sin.w, yr, bs="ts", k=20) ',
\end_layout

\begin_layout Quotation

\size scriptsize
' + s(plon, k=3, bs="ts") + s(plat, k=3, bs="ts") + s(plon, plat, k=20,
 bs="ts") ' ) ),
\end_layout

\end_deeper
\begin_layout Quotation

\size scriptsize
stmv_twostep_space = "fft",
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_fft_filter="matern", # matern, krige (very slow), lowpass, lowpass_matern
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_local_model_distanceweighted = TRUE,
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_gam_optimizer=c("outer", "bfgs") ,
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_variogram_method = "gstat",
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_distance_statsgrid = 2, # resolution (km) of data aggregation (i.e.
 generation of the ** statistics ** )
\end_layout

\begin_layout Quotation

\size scriptsize
stmv_distance_scale = c(40, 50, 60)
\end_layout

\end_deeper
\begin_layout Quotation

\size scriptsize
)
\end_layout

\begin_layout Quotation

\size scriptsize
# range( INP$snowcrab.large.males_abundance )
\end_layout

\begin_layout Quotation

\size scriptsize
# [1] 14.3 6675.0
\end_layout

\begin_layout Quotation

\size scriptsize
# o = snowcrab_stmv(p=p, DS="stmv_inputs" ) # create fields for
\end_layout

\begin_layout Quotation

\size scriptsize
stmv( p=p, runmode=c("globalmodel", "interpolate" ) ) # for a clean start
\end_layout

\begin_layout Quotation

\size scriptsize
# stmv( p=p, runmode=c("globalmodel", "interpolate" ), use_saved_state=TRUE
 ) # for a restart ..
 not working?
\end_layout

\begin_layout Quotation

\size scriptsize
# if (really.finished) stmv_db( p=p, DS="cleanup.all" )
\end_layout

\begin_layout Quotation

\size scriptsize
snowcrab_stmv( p=p, DS="predictions.redo" ) # warp predictions to other grids
 (if any)
\end_layout

\begin_layout Quotation

\size scriptsize
snowcrab_stmv( p=p, DS="stmv.stats.redo" ) # warp stats to other grids (if
 any)
\end_layout

\begin_layout Section
References and useful papers
\end_layout

\begin_layout Standard
Banerjee, S., Carlin, B.
 P., and Gelfand, A.
 E..
 2004.
 Hierarchical Modeling and Analysis for Spatial Data.
 Monographs on Statistics and Applied Probability.
 Chapman and Hall/CRC.
\end_layout

\begin_layout Standard
Cooley, James W.; Tukey, John W.
 (1965).
 "An algorithm for the machine calculation of complex Fourier series".
 Mathematics of Computation.
 19 (90): 297–301.
 doi:10.1090/S0025-5718-1965-0178586-1.
 ISSN 0025-5718.
\end_layout

\begin_layout Standard
Danielson, Gordon C.; Lanczos, Cornelius (1942).
 "Some improvements in practical Fourier analysis and their application
 to x-ray scattering from liquids".
 Journal of the Franklin Institute.
 233 (4): 365–380.
 doi:10.1016/S0016-0032(42)90767-1.) 
\end_layout

\begin_layout Standard
Fotheringham, A.
 S., Brunsdon, C., and Charlton, M.
 E.
 (2002).
 Geographically Weighted Regression: The Analysis of Spatially Varying Relations
hips.
 Wiley, Chichester.
\end_layout

\begin_layout Standard
Fourier, J.
 1822.
 Théorie analytique de la chaleur.
 Paris: Firmin Didot Père et Fils.
 1822.
 
\end_layout

\begin_layout Standard
Fuentes, M.
 (2001), A high frequency kriging approach for non‐stationary environmental
 processes.
 Environmetrics, 12: 469-483.
 doi:10.1002/env.473 )
\end_layout

\begin_layout Standard
Heideman, Michael T.; Johnson, Don H.; Burrus, Charles Sidney (1985-09-01).
 "Gauss and the history of the fast Fourier transform".
 Archive for History of Exact Sciences.
 34 (3): 265–277.
 CiteSeerX 10.1.1.309.181.
 doi:10.1007/BF00348431.
 ISSN 0003-9519.), 
\end_layout

\begin_layout Standard
Hengl, T., Heuvelink, G.B.M., and Stein, A.
 2004.
 A generic framework for spatial prediction of soil variables based on regressio
n-kriging.
 Geoderma 120: 75-93.
\end_layout

\begin_layout Standard
Huang, H.-C., and Hsu, N.-J.
 2004.
 Modeling transport effects on ground-level ozone using a non-stationary
 space-time model.
 Environmetrics 15 (3), 251–268.
\end_layout

\begin_layout Standard
Khintchine, Alexander (1934).
 "Korrelationstheorie der stationären stochastischen Prozesse".
 Mathematische Annalen.
 109 (1): 604–615.
 doi:10.1007/BF01449156.
\end_layout

\begin_layout Standard
Kostylev, Vladimir and Hannah, Charles.
 2007.
 Process-driven characterization and mapping of seabed habitats.
 Special Paper - Geological Association of Canada.
 47: 171-184.
\end_layout

\begin_layout Standard
Lindgren, F., Rue, H., and Lindstrom, J.
 2011.
 An explicit link between Gaussian fields and Gaussian Markov random fields:
 the stochastic partial differential equation approach.
 Journal of the Royal Statistical Society: Series B (Statistical Methodology)
 73: 423–498.
\end_layout

\begin_layout Standard
Nychka, D., Furrer, R., Paige, J., Sain S.
 2017.
 “fields: Tools for spatial data.” doi: 10.5065/D6W957CT (URL: https://doi.org/10.50
65/D6W957CT), R package version 9.8-3, <URL: https://github.com/NCAR/Fields>.
\end_layout

\begin_layout Standard
Robertson, C., & George, S.
 C.
 (2012).
 Theory and practical recommendations for autocorrelation-based image correlatio
n spectroscopy.
 Journal of biomedical optics, 17(8), 080801.
 doi:10.1117/1.JBO.17.8.080801 [https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3414238/]
\end_layout

\begin_layout Standard
Sigrist, F., Künsch, H.
 R., and Stahel, W.
 A.
 2012.
 A dynamic nonstationary spatio-temporal model for short term prediction
 of precipitation.
 Ann.
 Appl.
 Statist.
 6: 1452–1477.
\end_layout

\begin_layout Standard
Sølna, K., and Switzer, P.
 .1996.
 Time trend estimation for a geographic region.
 Journal of the American Statistical Association 91: 577–589.
\end_layout

\begin_layout Standard
Wiener, Norbert (1930).
 "Generalized Harmonic Analysis".
 Acta Mathematica.
 55: 117–258.
 ; 
\end_layout

\begin_layout Standard
Wikle, C.K., and Cressie, N.
 1999.
 A dimension-reduced approach to space-time Kalman filtering.
 Biometrika 86: 815–829.
\end_layout

\begin_layout Standard
Yates, Frank (1937).
 "The design and analysis of factorial experiments".
 Technical Communication no.
 35 of the Commonwealth Bureau of Soils.
 
\end_layout

\begin_layout Standard
Xu, K., Wikle, C.
 K., and N.
 I.
 Fox.
 2005.
 A kernel-based spatio-temporal dynamical model for nowcasting weather radar
 reflectivities.
 Journal of the American Statistical Association 100: 1133–1144.
\end_layout

\end_body
\end_document
